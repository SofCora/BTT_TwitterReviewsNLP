{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Implement Your Machine Learning Project Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose the twitter sentiment analysis dataset becasue I wanted to expand upon NLP and learn more about deep neural networks. \n",
    "\n",
    "I found that most of the tweets in my dataset were actually reviews of different products, video games, and web services so a model like this could be further implememented by companies to gague public reception of their new products on social media. For twitter itself, this model could be used to determine which products users like and which ads to run on the site\n",
    "\n",
    "The overall structure of my model is word embeddings that are mapped to tokens and fed into a recurrent neural network. The word embeddings are input using an embedding layer, it goes through 2 LSTM layers and then an output layer.\n",
    "I wanted to use word embeddings because they aren't sparse like other vectorizers and uitilzes the semantic context between each word through cosine similarity.\n",
    "\n",
    "Because what I wanted to do was a bit out of the scope of what we covered in class, I used the following resources to create a shell for my model and figure out how to process word embeddings: \n",
    "<a href=\"https://towardsdatascience.com/machine-learning-word-embedding-sentiment-classification-using-keras-b83c28087456\">word embeddings tutoiral</a>\n",
    "<a href=\"https://www.google.com/url?q=https://stackoverflow.com/questions/38250710/how-to-split-data-into-3-sets-train-validation-and-test&sa=D&source=docs&ust=1691811932916951&usg=AOvVaw04Jx8dffs2JwJipeaD3cKQ\">how to split data into a val set</a>\n",
    "<a href=\"https://keras.io/guides/working_with_rnns/#:~:text=model%20%3D%20keras.Sequential%28%29%20%23%20Add%20an%20Embedding%20layer,a%20Dense%20layer%20with%2010%20units.%20model.add%28layers.Dense%2810%29%29%20model.summary%28%29\">Keras RNN Documentation</a>\n",
    "<a href=\"https://danijar.com/tips-for-training-recurrent-neural-networks/\">Optimizing</a>\n",
    "<a href=\"https://machinelearningmastery.com/gentle-introduction-long-short-term-memory-networks-experts/\">LSTM</a>\n",
    "<a href=\"https://www.bing.com/search?q=gru+layers+in+rnn&cvid=d4fca12d48024661902a22055ced9c00&aqs=edge.0.69i59j69i57j0l5j46j69i60.1461j0j9&FORM=ANAB01&PC=U531\">GRU</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "\n",
    "Before you get started, import a few packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from seaborn) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from seaborn) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.1.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (10.0.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.42.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.57.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: packaging in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.41.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.57.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.41.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (4.3.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from gensim) (1.11.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from gensim) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade scikit-learn\n",
    "%pip install --upgrade tensorflow\n",
    "%pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> In the code cell below, import additional packages that you have used in this course that you will need for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- -----------\n",
      "absl-py                      1.4.0\n",
      "asttokens                    2.2.1\n",
      "astunparse                   1.6.3\n",
      "backcall                     0.2.0\n",
      "cachetools                   5.3.1\n",
      "certifi                      2023.7.22\n",
      "charset-normalizer           3.2.0\n",
      "click                        8.1.6\n",
      "colorama                     0.4.6\n",
      "comm                         0.1.4\n",
      "contourpy                    1.1.0\n",
      "cycler                       0.11.0\n",
      "debugpy                      1.6.7.post1\n",
      "decorator                    5.1.1\n",
      "executing                    1.2.0\n",
      "flatbuffers                  23.5.26\n",
      "fonttools                    4.42.0\n",
      "gast                         0.4.0\n",
      "gensim                       4.3.1\n",
      "google-auth                  2.22.0\n",
      "google-auth-oauthlib         1.0.0\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.57.0\n",
      "h5py                         3.9.0\n",
      "idna                         3.4\n",
      "ipykernel                    6.25.1\n",
      "ipython                      8.14.0\n",
      "jedi                         0.19.0\n",
      "joblib                       1.3.2\n",
      "jupyter_client               8.3.0\n",
      "jupyter_core                 5.3.1\n",
      "keras                        2.13.1\n",
      "kiwisolver                   1.4.4\n",
      "libclang                     16.0.6\n",
      "Markdown                     3.4.4\n",
      "MarkupSafe                   2.1.3\n",
      "matplotlib                   3.7.2\n",
      "matplotlib-inline            0.1.6\n",
      "nest-asyncio                 1.5.7\n",
      "nltk                         3.8.1\n",
      "numpy                        1.24.3\n",
      "oauthlib                     3.2.2\n",
      "opt-einsum                   3.3.0\n",
      "packaging                    23.1\n",
      "pandas                       2.0.3\n",
      "parso                        0.8.3\n",
      "pickleshare                  0.7.5\n",
      "Pillow                       10.0.0\n",
      "pip                          23.0.1\n",
      "platformdirs                 3.10.0\n",
      "prompt-toolkit               3.0.39\n",
      "protobuf                     4.24.0\n",
      "psutil                       5.9.5\n",
      "pure-eval                    0.2.2\n",
      "pyasn1                       0.5.0\n",
      "pyasn1-modules               0.3.0\n",
      "Pygments                     2.16.1\n",
      "pyparsing                    3.0.9\n",
      "python-dateutil              2.8.2\n",
      "pytz                         2023.3\n",
      "pywin32                      306\n",
      "pyzmq                        25.1.1\n",
      "regex                        2023.8.8\n",
      "requests                     2.31.0\n",
      "requests-oauthlib            1.3.1\n",
      "rsa                          4.9\n",
      "scikeras                     0.11.0\n",
      "scikit-learn                 1.3.0\n",
      "scipy                        1.11.1\n",
      "seaborn                      0.12.2\n",
      "setuptools                   65.5.0\n",
      "six                          1.16.0\n",
      "smart-open                   6.3.0\n",
      "stack-data                   0.6.2\n",
      "tensorboard                  2.13.0\n",
      "tensorboard-data-server      0.7.1\n",
      "tensorflow                   2.13.0\n",
      "tensorflow-estimator         2.13.0\n",
      "tensorflow-intel             2.13.0\n",
      "tensorflow-io-gcs-filesystem 0.31.0\n",
      "termcolor                    2.3.0\n",
      "threadpoolctl                3.2.0\n",
      "tornado                      6.3.3\n",
      "tqdm                         4.66.1\n",
      "traitlets                    5.9.0\n",
      "typing_extensions            4.5.0\n",
      "tzdata                       2023.3\n",
      "urllib3                      1.26.16\n",
      "wcwidth                      0.2.6\n",
      "Werkzeug                     2.3.6\n",
      "wheel                        0.41.1\n",
      "wrapt                        1.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import tensorflow\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import keras as keras\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras import layers\n",
    "import gensim\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load the Data Set\n",
    "\n",
    "\n",
    "Dataset Source: <a href=\"https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis\">Kaggle</a>\n",
    "The orginial dataset had an id, an entity the tweet was about, the tweet itself, and the sentiment attached to the tweet. The original challenge was to do sentiment analysis based on the entity the tweet was about however I wanted to conduct an analysis based on the text in the tweet. Also the sentiments were either postivie, neutral, or negative but to simplify I only used the positive and negative tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "filename = os.path.join(os.getcwd(), \"twitter_training.csv\")\n",
    "df_og = pd.read_csv(filename, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df_og[['is_Positive', 'Review']]\n",
    "df = df[(df['is_Positive'] == 'Positive') | (df['is_Positive'] == 'Negative')]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploratory Data Analysis\n",
    "\n",
    "\n",
    "This step will help you determine data preparation and feature engineering techniques you will need to apply to your data to build a balanced modeling data set for your problem and model. These data preparation techniques may include:\n",
    "* addressing missingness, such as replacing missing values with means\n",
    "* renaming features and labels\n",
    "* finding and replacing outliers\n",
    "* performing winsorization if needed\n",
    "* performing one-hot encoding on categorical features\n",
    "* performing vectorization for an NLP problem\n",
    "* addressing class imbalance in your data sample to promote fair AI\n",
    "\n",
    "\n",
    "<h2>EDA</h2>\n",
    "I made it so the dataset only contained the columns sentiment and tweet and then took out any tweet with the sentiment Neutral so I could have binary values for the sentiment column. The values for the is_Positive (sentiment) column were now 'Positive' and 'Negative' but I used pd.apply to map those values to binary numbers.\n",
    "\n",
    " Checked for class imbalance and dropped any null values, I didn't modify null values because the dataset was so large to begin with. (Around 40k examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are there any null values? is_Positive    False\n",
      "Review          True\n",
      "dtype: bool\n",
      "\n",
      "\n",
      "is_Positive    False\n",
      "Review         False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.drop(df[df.Review ==  'Neutral'].index, inplace=True)\n",
    "def map_sentiment(sentiment):\n",
    "    if sentiment == 'Positive':\n",
    "        return 1\n",
    "    if sentiment == 'Negative':\n",
    "        return 0\n",
    "    else:\n",
    "        raise ValueError(\"Unknown sentiment: \" + sentiment)\n",
    "\n",
    "df['is_Positive'] = df['is_Positive'].apply(map_sentiment)\n",
    "\n",
    "print('are there any null values?', df.isna().any())\n",
    "print('\\n')\n",
    "df.dropna(inplace=True)\n",
    "#I just dropped the rows that have null values\n",
    "print(df.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many negative reviews are there: 22358\n",
      "how many positive reviews are there: 20655\n",
      "in my opinion theres little class imbalance cuz theres only 2000 more negative reviews than positive\n"
     ]
    }
   ],
   "source": [
    "print('how many negative reviews are there:', df['is_Positive'].value_counts()[0])\n",
    "print('how many positive reviews are there:', df['is_Positive'].value_counts()[1])\n",
    "print('in my opinion theres little class imbalance cuz theres only 2000 more negative reviews than positive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_Positive</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_Positive                                             Review\n",
       "0            1  im getting on borderlands and i will murder yo...\n",
       "1            1  I am coming to the borders and I will kill you...\n",
       "2            1  im getting on borderlands and i will kill you ...\n",
       "3            1  im coming on borderlands and i will murder you...\n",
       "4            1  im getting on borderlands 2 and i will murder ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Possible Bias in Dataset </h2>\n",
    "I noticed the number of positive reviews with male pronouns was double\n",
    "the amount of positive reviews with female pronouns, implying there's more positive reviews for products/services involving men.\n",
    "I decided to use gendered pronouns as a stopwords list to clean the data with to prevent gender bias as a preventative measure.\n",
    "If I hadn't the model could fall into allocative bias, not recommending products/services for/by women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many reviews with male pronouns that are positive: 402\n",
      "how many reviews with female pronouns are positive: 247\n"
     ]
    }
   ],
   "source": [
    "female_pronouns = [ 'she', 'her']\n",
    "male_pronouns = ['he', 'him', 'his']\n",
    "\n",
    "# Combine the target words into a regular expression pattern\n",
    "m_pattern = r'\\b(?:' + '|'.join(male_pronouns) + r')\\b'\n",
    "f_pattern =  r'\\b(?:' + '|'.join(female_pronouns) + r')\\b'\n",
    "\n",
    "male_df = df[df['Review'].str.contains(m_pattern, case=False, na=False)]\n",
    "female_df = df[df['Review'].str.contains(f_pattern, case=False, na=False)]\n",
    "print('how many reviews with male pronouns that are positive:', (male_df['is_Positive'] == 1).sum())\n",
    "print('how many reviews with female pronouns are positive:',(female_df['is_Positive'] == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from nltk) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: click in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sofia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sofia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preprocess Data and Tokenize it</h2>\n",
    "While cutting stopwords usually improves model performance, I noticed that the more stopwords I excluded, the worse the model performed, this could be because I'm not working with very long documents (each review is a paragraph each) or because the word vectors/ RNN are able to better use the context of stopwords to make predictions.\n",
    "So i only took out the gendered pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many examples :  43013\n"
     ]
    }
   ],
   "source": [
    "review_lines = []  # Initialize the list to store cleaned lines exmpale:: ['im', 'totally', 'getting', 'this', 'game']\n",
    "\n",
    "# Preprocess the lines using simple_preprocess and remove stop words\n",
    "lines = df['Review']\n",
    "stop_words = ['he', 'his', 'him', 'she', 'her', 'hers']\n",
    "\n",
    "for line in lines:\n",
    "    \n",
    "    cleaned_line = [word for word in gensim.utils.simple_preprocess(line) if word not in stop_words]\n",
    "    review_lines.append(cleaned_line)\n",
    "    \n",
    "    \n",
    "\n",
    "print('how many examples : ',len(review_lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Creating the Word Embeddings Using Word2Vec</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size 18710\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "model = gensim.models.Word2Vec(sentences = review_lines, vector_size = EMBEDDING_DIM, window = 8, workers = 4, min_count = 1)\n",
    "words = list(model.wv.key_to_index)\n",
    "print('vocabulary size', len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('standard', 0.8962534666061401),\n",
       " ('possibly', 0.8725541830062866),\n",
       " ('perhaps', 0.8694287538528442),\n",
       " ('nintendo', 0.8499842882156372),\n",
       " ('fortnites', 0.847375214099884),\n",
       " ('newly', 0.844363808631897),\n",
       " ('seventh', 0.8441952466964722),\n",
       " ('inside', 0.8410889506340027),\n",
       " ('amongst', 0.8410755395889282),\n",
       " ('trailers', 0.8371947407722473)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('trilogy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Creating a Dictionary With Word:Vector Pairs</h2>\n",
    "Save the model into a text file which is the word and then a 100 length vector for each line\n",
    "model is saved into a txt file then iterated line by line to tokenize (split up) the word from the values\n",
    "embeddings_dictionary is {word_in_review : 100_num_vector}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the wordembeddings as a dict of words to vectors\n",
    "filename = 'twitter_training_word2vec.txt'\n",
    "model.wv.save_word2vec_format(filename, binary = False)\n",
    "embeddings_dictionary = {}\n",
    "f = open(os.path.join('', 'twitter_training_word2vec.txt'), encoding = 'utf-8')\n",
    "#embeddings_dictionary one line of f is the word corresponding with a long integer vector\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_dictionary[word] = coefs\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't just put the word vectors straight into a neural network \n",
    "so they need to be tokenized and put into an embedding layer rather than as input for like a normal dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert word embedding into a tokenized vector. maps to the index of a single vector in the embeddings layer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(review_lines)\n",
    "#tokenize (split up) each word in the total vocabulary with tokenizer_obj\n",
    "sequences = tokenizer_obj.texts_to_sequences(review_lines)\n",
    "#Each integer in these sequences represents a token from the original text. Returns sequences of integers\n",
    "# This is typically done by mapping each token to a unique integer based on the tokenizer's internal vocabulary\n",
    "\n",
    "\n",
    "word_index = tokenizer_obj.word_index\n",
    "#word index is like a dictionary of a word and a number 1-20843\n",
    "review_pad = pad_sequences(sequences, maxlen = 100)\n",
    "#so in each index of review pad is a bunch of numbers based on the embeddings\n",
    "# theres always 100 numbers at each index because thats what maxlen is\n",
    "#if vector is <100 then add 0s\n",
    "is_Positive = df['is_Positive'].values\n",
    "#max_len is a tunable hyperparameter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so now were mapping the embeddings from word2vec to the tokenized vocab to make a matrix\n",
    "num_words = len(word_index)+1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "#embedding_matrix is the final var that you input into the embedding layer in final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Implement Your Project Plan\n",
    "\n",
    "\n",
    "1. Prepare your data for your model and create features and a label.\n",
    "2. Fit your model to the training data and evaluate your model.\n",
    "3. Improve your model by performing model selection and/or feature selection techniques to find best model for your problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Im going to create the neural net starting with an embedding layer that will take in our sequences/embeddings/dictionary/matrices. Also make a grid search algorithmn to find the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.57.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.41.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU \n",
    "#those are diff types of rnn layers\n",
    "\n",
    "from keras.initializers import Constant\n",
    "from keras.metrics import AUC, Precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>What are the RNN Layers?</h2>\n",
    "<ul>\n",
    "    <li>Embedding - maps input information from a high-dimensional to a lower-dimensional space</li>\n",
    "<li>LSTM - Solves the vanishing gradient problem (gradient becomes too small to update weights) cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the layer. theres a memory cell, Forget gate, input and output gates</li>\n",
    "<li>GRU - Like LSTM but fewer parameters and lacks an output gate. Reset and update gates no long range memory cell</li>\n",
    "</ul>\n",
    "\n",
    "Now I'm going to do a train/val/split where validation set is 20% of the total data\n",
    "basically u take the review_pad sequence, randomize all the indices and the data up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(review_pad.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "review_pad = review_pad[indices]\n",
    "is_Positive = is_Positive[indices]\n",
    "\n",
    "\n",
    "#so idk how to get 3 splits with train_test_split so i did two test train splits on top of each other\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(review_pad,is_Positive,test_size=0.2,train_size=0.8)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size = 0.25,train_size =0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (2.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Performing A Grid Search For Best Params </h2>\n",
    "I'm trying to optimize the number of units for each layer, the optimizer function (Learning rate), and the dropout rate.\n",
    "\n",
    "Note:: The grid search took forever so I could really only look for two hyperparameters at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: scikeras in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.57.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.41.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sofia\\downloads\\btt\\final_project\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install tensorflow scikeras scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 228ms/step - loss: 0.6959 - auc_925: 0.4871\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 276ms/step - loss: 0.6931 - auc_925: 0.5161\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 411ms/step - loss: 0.6922 - auc_925: 0.5454\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 396ms/step - loss: 0.6940 - auc_925: 0.5116\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 398ms/step - loss: 0.6915 - auc_925: 0.5606\n",
      "13/13 [==============================] - 2s 49ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 21s 422ms/step - loss: 0.6911 - auc_926: 0.5390\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 423ms/step - loss: 0.6907 - auc_926: 0.5457\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 402ms/step - loss: 0.6920 - auc_926: 0.5440\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 416ms/step - loss: 0.6876 - auc_926: 0.5739\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 421ms/step - loss: 0.6873 - auc_926: 0.5699\n",
      "13/13 [==============================] - 2s 46ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 24s 431ms/step - loss: 0.6898 - auc_927: 0.5301\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 402ms/step - loss: 0.6900 - auc_927: 0.5338\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 282ms/step - loss: 0.6935 - auc_927: 0.5187\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 2s 213ms/step - loss: 0.6883 - auc_927: 0.5501\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 240ms/step - loss: 0.6870 - auc_927: 0.5840\n",
      "13/13 [==============================] - 1s 27ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 15s 452ms/step - loss: 0.6978 - auc_928: 0.4591\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 454ms/step - loss: 0.6943 - auc_928: 0.4925\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 453ms/step - loss: 0.6941 - auc_928: 0.4916\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 2s 294ms/step - loss: 0.6916 - auc_928: 0.5429\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.6915 - auc_928: 0.5421\n",
      "13/13 [==============================] - 1s 18ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 6s 155ms/step - loss: 0.6963 - auc_929: 0.4742\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 1s 167ms/step - loss: 0.6929 - auc_929: 0.5129\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 1s 166ms/step - loss: 0.6924 - auc_929: 0.5455\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 1s 156ms/step - loss: 0.6904 - auc_929: 0.5547\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 1s 156ms/step - loss: 0.6912 - auc_929: 0.5623\n",
      "13/13 [==============================] - 1s 17ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 7s 217ms/step - loss: 0.6945 - auc_930: 0.4981\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 238ms/step - loss: 0.6902 - auc_930: 0.5417\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 230ms/step - loss: 0.6881 - auc_930: 0.5517\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 2s 233ms/step - loss: 0.6899 - auc_930: 0.5556\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 234ms/step - loss: 0.6849 - auc_930: 0.5688\n",
      "13/13 [==============================] - 1s 18ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 7s 222ms/step - loss: 0.6938 - auc_931: 0.4966\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 250ms/step - loss: 0.6925 - auc_931: 0.5325\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 246ms/step - loss: 0.6904 - auc_931: 0.5671\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 2s 240ms/step - loss: 0.6916 - auc_931: 0.5351\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 242ms/step - loss: 0.6894 - auc_931: 0.5700\n",
      "13/13 [==============================] - 1s 20ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 8s 190ms/step - loss: 0.6953 - auc_932: 0.4779\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 237ms/step - loss: 0.6921 - auc_932: 0.5339\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 243ms/step - loss: 0.6927 - auc_932: 0.5164\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 2s 241ms/step - loss: 0.6933 - auc_932: 0.5160\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 239ms/step - loss: 0.6927 - auc_932: 0.5730\n",
      "13/13 [==============================] - 1s 20ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 7s 225ms/step - loss: 0.6928 - auc_933: 0.5083\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 244ms/step - loss: 0.6930 - auc_933: 0.5059\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 235ms/step - loss: 0.6920 - auc_933: 0.5496\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 2s 242ms/step - loss: 0.6868 - auc_933: 0.5674\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 237ms/step - loss: 0.6873 - auc_933: 0.5586\n",
      "13/13 [==============================] - 1s 19ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 7s 255ms/step - loss: 0.7000 - auc_934: 0.4440\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 268ms/step - loss: 0.6939 - auc_934: 0.5249\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 269ms/step - loss: 0.6951 - auc_934: 0.5179\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 2s 260ms/step - loss: 0.6930 - auc_934: 0.5162\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 273ms/step - loss: 0.6924 - auc_934: 0.5591\n",
      "13/13 [==============================] - 1s 24ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 7s 249ms/step - loss: 0.6980 - auc_935: 0.4762\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 264ms/step - loss: 0.6941 - auc_935: 0.5281\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 270ms/step - loss: 0.6944 - auc_935: 0.4975\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 2s 263ms/step - loss: 0.6910 - auc_935: 0.5471\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 269ms/step - loss: 0.6897 - auc_935: 0.5557\n",
      "13/13 [==============================] - 1s 20ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 8s 203ms/step - loss: 0.6942 - auc_936: 0.4870\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 263ms/step - loss: 0.6923 - auc_936: 0.4951\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 270ms/step - loss: 0.6902 - auc_936: 0.5289\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 2s 262ms/step - loss: 0.6896 - auc_936: 0.5317\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 268ms/step - loss: 0.6871 - auc_936: 0.5633\n",
      "13/13 [==============================] - 1s 23ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 7s 299ms/step - loss: 0.6919 - auc_937: 0.5268\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 318ms/step - loss: 0.6916 - auc_937: 0.5579\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 304ms/step - loss: 0.6924 - auc_937: 0.5348\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 2s 300ms/step - loss: 0.6912 - auc_937: 0.5457\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 292ms/step - loss: 0.6894 - auc_937: 0.5536\n",
      "13/13 [==============================] - 1s 22ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 7s 288ms/step - loss: 0.6938 - auc_938: 0.5131\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 308ms/step - loss: 0.6920 - auc_938: 0.5322\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 300ms/step - loss: 0.6934 - auc_938: 0.5182\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 2s 304ms/step - loss: 0.6905 - auc_938: 0.5393\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 297ms/step - loss: 0.6870 - auc_938: 0.5650\n",
      "13/13 [==============================] - 1s 23ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 7s 304ms/step - loss: 0.6921 - auc_939: 0.5192\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 307ms/step - loss: 0.6896 - auc_939: 0.5538\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 307ms/step - loss: 0.6870 - auc_939: 0.5711\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 2s 297ms/step - loss: 0.6929 - auc_939: 0.5318\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 308ms/step - loss: 0.6865 - auc_939: 0.5632\n",
      "13/13 [==============================] - 1s 22ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 7s 339ms/step - loss: 0.6924 - auc_940: 0.5336\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 358ms/step - loss: 0.6955 - auc_940: 0.5289\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 346ms/step - loss: 0.6922 - auc_940: 0.5716\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 353ms/step - loss: 0.6892 - auc_940: 0.5648\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 336ms/step - loss: 0.6906 - auc_940: 0.5616\n",
      "13/13 [==============================] - 1s 26ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 8s 306ms/step - loss: 0.6955 - auc_941: 0.4742\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 347ms/step - loss: 0.6928 - auc_941: 0.5222\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 352ms/step - loss: 0.6914 - auc_941: 0.5429\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 368ms/step - loss: 0.6900 - auc_941: 0.5572\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 344ms/step - loss: 0.6872 - auc_941: 0.5717\n",
      "13/13 [==============================] - 1s 29ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 7s 339ms/step - loss: 0.6927 - auc_942: 0.5163\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 357ms/step - loss: 0.6914 - auc_942: 0.5368\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 376ms/step - loss: 0.6899 - auc_942: 0.5515\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 2s 341ms/step - loss: 0.6870 - auc_942: 0.5605\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 343ms/step - loss: 0.6893 - auc_942: 0.5590\n",
      "13/13 [==============================] - 1s 30ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 8s 396ms/step - loss: 0.6951 - auc_943: 0.4762\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 401ms/step - loss: 0.6900 - auc_943: 0.5732\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 404ms/step - loss: 0.6885 - auc_943: 0.5718\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 406ms/step - loss: 0.6879 - auc_943: 0.5596\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 399ms/step - loss: 0.6865 - auc_943: 0.5691\n",
      "13/13 [==============================] - 1s 26ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 8s 389ms/step - loss: 0.6945 - auc_944: 0.5036\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 403ms/step - loss: 0.6944 - auc_944: 0.5018\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 418ms/step - loss: 0.6919 - auc_944: 0.5470\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 397ms/step - loss: 0.6893 - auc_944: 0.5488\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 399ms/step - loss: 0.6912 - auc_944: 0.5419\n",
      "13/13 [==============================] - 1s 27ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 325ms/step - loss: 0.6902 - auc_945: 0.5441\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 422ms/step - loss: 0.6942 - auc_945: 0.5167\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 411ms/step - loss: 0.6919 - auc_945: 0.5537\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 413ms/step - loss: 0.6912 - auc_945: 0.5373\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 424ms/step - loss: 0.6879 - auc_945: 0.5647\n",
      "13/13 [==============================] - 1s 30ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 7s 240ms/step - loss: 0.6980 - auc_946: 0.4726\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 249ms/step - loss: 0.6879 - auc_946: 0.5760\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 252ms/step - loss: 0.6921 - auc_946: 0.5514\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 2s 273ms/step - loss: 0.6879 - auc_946: 0.5724\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 273ms/step - loss: 0.6858 - auc_946: 0.5841\n",
      "13/13 [==============================] - 1s 23ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 7s 253ms/step - loss: 0.6999 - auc_947: 0.4721\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 252ms/step - loss: 0.6896 - auc_947: 0.5624\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 258ms/step - loss: 0.6922 - auc_947: 0.5473\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 2s 253ms/step - loss: 0.6876 - auc_947: 0.5649\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 274ms/step - loss: 0.6851 - auc_947: 0.5774\n",
      "13/13 [==============================] - 1s 21ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 7s 267ms/step - loss: 0.6973 - auc_948: 0.5155\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 269ms/step - loss: 0.6933 - auc_948: 0.5104\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 282ms/step - loss: 0.6879 - auc_948: 0.5643\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 2s 268ms/step - loss: 0.6829 - auc_948: 0.5849\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 280ms/step - loss: 0.6852 - auc_948: 0.5678\n",
      "13/13 [==============================] - 1s 22ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 7s 303ms/step - loss: 0.6953 - auc_949: 0.4994\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 317ms/step - loss: 0.6906 - auc_949: 0.5474\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 320ms/step - loss: 0.6870 - auc_949: 0.5787\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 2s 335ms/step - loss: 0.6902 - auc_949: 0.5552\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 314ms/step - loss: 0.6847 - auc_949: 0.5875\n",
      "13/13 [==============================] - 1s 24ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 322ms/step - loss: 0.6949 - auc_950: 0.5213\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 355ms/step - loss: 0.6904 - auc_950: 0.5432\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 329ms/step - loss: 0.6891 - auc_950: 0.5562\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 2s 344ms/step - loss: 0.6881 - auc_950: 0.5776\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 326ms/step - loss: 0.6933 - auc_950: 0.5458\n",
      "13/13 [==============================] - 1s 27ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 8s 344ms/step - loss: 0.6998 - auc_951: 0.4824\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 331ms/step - loss: 0.6936 - auc_951: 0.5208\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 357ms/step - loss: 0.6871 - auc_951: 0.5623\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 365ms/step - loss: 0.6862 - auc_951: 0.5763\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 338ms/step - loss: 0.6870 - auc_951: 0.5624\n",
      "13/13 [==============================] - 1s 26ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 8s 384ms/step - loss: 0.6970 - auc_952: 0.5136\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 381ms/step - loss: 0.6914 - auc_952: 0.5447\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 393ms/step - loss: 0.6861 - auc_952: 0.5692\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 401ms/step - loss: 0.6916 - auc_952: 0.5643\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 381ms/step - loss: 0.6860 - auc_952: 0.5737\n",
      "13/13 [==============================] - 1s 33ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 399ms/step - loss: 0.6979 - auc_953: 0.4854\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 415ms/step - loss: 0.6942 - auc_953: 0.5265\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 395ms/step - loss: 0.6917 - auc_953: 0.5373\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 397ms/step - loss: 0.6919 - auc_953: 0.5328\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 401ms/step - loss: 0.6907 - auc_953: 0.5543\n",
      "13/13 [==============================] - 1s 28ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 403ms/step - loss: 0.6965 - auc_954: 0.5027\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 395ms/step - loss: 0.6944 - auc_954: 0.4971\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 392ms/step - loss: 0.6897 - auc_954: 0.5469\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 409ms/step - loss: 0.6937 - auc_954: 0.5305\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 383ms/step - loss: 0.6827 - auc_954: 0.5845\n",
      "13/13 [==============================] - 1s 30ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 429ms/step - loss: 0.7042 - auc_955: 0.4970\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 0.6982 - auc_955: 0.4990\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 436ms/step - loss: 0.6946 - auc_955: 0.5034\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 440ms/step - loss: 0.6910 - auc_955: 0.5603\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 0.6900 - auc_955: 0.5678\n",
      "13/13 [==============================] - 1s 35ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 428ms/step - loss: 0.6961 - auc_956: 0.5028\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 434ms/step - loss: 0.6982 - auc_956: 0.4670\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.6922 - auc_956: 0.5342\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 420ms/step - loss: 0.6916 - auc_956: 0.5370\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.6908 - auc_956: 0.5445\n",
      "13/13 [==============================] - 1s 33ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 436ms/step - loss: 0.6911 - auc_957: 0.5219\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 423ms/step - loss: 0.6861 - auc_957: 0.5678\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.6883 - auc_957: 0.5563\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 445ms/step - loss: 0.6906 - auc_957: 0.5524\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 439ms/step - loss: 0.6853 - auc_957: 0.5674\n",
      "13/13 [==============================] - 1s 31ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 463ms/step - loss: 0.6978 - auc_958: 0.4837\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 465ms/step - loss: 0.6888 - auc_958: 0.5720\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 473ms/step - loss: 0.6884 - auc_958: 0.5639\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 467ms/step - loss: 0.6871 - auc_958: 0.5795\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 470ms/step - loss: 0.6873 - auc_958: 0.5662\n",
      "13/13 [==============================] - 1s 33ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 480ms/step - loss: 0.6969 - auc_959: 0.4998\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 484ms/step - loss: 0.6977 - auc_959: 0.5400\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 476ms/step - loss: 0.6894 - auc_959: 0.5586\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 458ms/step - loss: 0.6880 - auc_959: 0.5668\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 465ms/step - loss: 0.6883 - auc_959: 0.5559\n",
      "13/13 [==============================] - 1s 35ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 476ms/step - loss: 0.6957 - auc_960: 0.4873\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 479ms/step - loss: 0.6900 - auc_960: 0.5722\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 497ms/step - loss: 0.6870 - auc_960: 0.5557\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 472ms/step - loss: 0.6899 - auc_960: 0.5628\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 466ms/step - loss: 0.6980 - auc_960: 0.5297\n",
      "13/13 [==============================] - 1s 34ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 541ms/step - loss: 0.6951 - auc_961: 0.5194\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 549ms/step - loss: 0.6889 - auc_961: 0.5692\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 554ms/step - loss: 0.6896 - auc_961: 0.5552\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 551ms/step - loss: 0.6847 - auc_961: 0.5849\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 0.6876 - auc_961: 0.5798\n",
      "13/13 [==============================] - 1s 39ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 545ms/step - loss: 0.6958 - auc_962: 0.4829\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 556ms/step - loss: 0.6952 - auc_962: 0.5025\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 592ms/step - loss: 0.6916 - auc_962: 0.5770\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 555ms/step - loss: 0.6890 - auc_962: 0.5651\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 537ms/step - loss: 0.6870 - auc_962: 0.5730\n",
      "13/13 [==============================] - 1s 38ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 586ms/step - loss: 0.6924 - auc_963: 0.5108\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 583ms/step - loss: 0.6824 - auc_963: 0.5921\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 549ms/step - loss: 0.6876 - auc_963: 0.5506\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 558ms/step - loss: 0.6836 - auc_963: 0.5743\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 550ms/step - loss: 0.6830 - auc_963: 0.5794\n",
      "13/13 [==============================] - 1s 40ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 641ms/step - loss: 0.7006 - auc_964: 0.4852\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 618ms/step - loss: 0.6941 - auc_964: 0.5319\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 622ms/step - loss: 0.6903 - auc_964: 0.5491\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 630ms/step - loss: 0.6971 - auc_964: 0.5231\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 636ms/step - loss: 0.6910 - auc_964: 0.5565\n",
      "13/13 [==============================] - 1s 38ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 624ms/step - loss: 0.6919 - auc_965: 0.5308\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 625ms/step - loss: 0.6981 - auc_965: 0.5270\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 643ms/step - loss: 0.6917 - auc_965: 0.5540\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 630ms/step - loss: 0.6862 - auc_965: 0.5754\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 663ms/step - loss: 0.6871 - auc_965: 0.5629\n",
      "13/13 [==============================] - 1s 39ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 638ms/step - loss: 0.6903 - auc_966: 0.5360\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 618ms/step - loss: 0.6897 - auc_966: 0.5449\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 635ms/step - loss: 0.6867 - auc_966: 0.5645\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 612ms/step - loss: 0.6861 - auc_966: 0.5706\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 632ms/step - loss: 0.6815 - auc_966: 0.5735\n",
      "13/13 [==============================] - 1s 42ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 8s 351ms/step - loss: 0.6943 - auc_967: 0.5032\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 366ms/step - loss: 0.6928 - auc_967: 0.5224\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 371ms/step - loss: 0.6918 - auc_967: 0.5449\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 351ms/step - loss: 0.6864 - auc_967: 0.5720\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 366ms/step - loss: 0.6873 - auc_967: 0.5771\n",
      "13/13 [==============================] - 2s 30ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 384ms/step - loss: 0.7053 - auc_968: 0.4524\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 353ms/step - loss: 0.6930 - auc_968: 0.5171\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 358ms/step - loss: 0.6921 - auc_968: 0.5298\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 361ms/step - loss: 0.6929 - auc_968: 0.5332\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 365ms/step - loss: 0.6904 - auc_968: 0.5462\n",
      "13/13 [==============================] - 1s 31ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 8s 355ms/step - loss: 0.6917 - auc_969: 0.5138\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 355ms/step - loss: 0.6919 - auc_969: 0.5336\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 348ms/step - loss: 0.6873 - auc_969: 0.5709\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 371ms/step - loss: 0.6880 - auc_969: 0.5616\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 347ms/step - loss: 0.6851 - auc_969: 0.5713\n",
      "13/13 [==============================] - 1s 35ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 401ms/step - loss: 0.7001 - auc_970: 0.4766\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 445ms/step - loss: 0.6906 - auc_970: 0.5570\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 434ms/step - loss: 0.6895 - auc_970: 0.5612\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.6903 - auc_970: 0.5594\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 0.6888 - auc_970: 0.5530\n",
      "13/13 [==============================] - 2s 31ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 405ms/step - loss: 0.6998 - auc_971: 0.4729\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 401ms/step - loss: 0.6926 - auc_971: 0.5321\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 412ms/step - loss: 0.6904 - auc_971: 0.5394\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.6883 - auc_971: 0.5655\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 422ms/step - loss: 0.6931 - auc_971: 0.5395\n",
      "13/13 [==============================] - 1s 37ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 414ms/step - loss: 0.7021 - auc_972: 0.4779\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 405ms/step - loss: 0.6939 - auc_972: 0.5116\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 391ms/step - loss: 0.6896 - auc_972: 0.5343\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 408ms/step - loss: 0.6915 - auc_972: 0.5496\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 410ms/step - loss: 0.6867 - auc_972: 0.5688\n",
      "13/13 [==============================] - 1s 31ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 443ms/step - loss: 0.6927 - auc_973: 0.5313\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 436ms/step - loss: 0.6942 - auc_973: 0.5343\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 438ms/step - loss: 0.6925 - auc_973: 0.5493\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 433ms/step - loss: 0.6895 - auc_973: 0.5519\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 437ms/step - loss: 0.6897 - auc_973: 0.5695\n",
      "13/13 [==============================] - 1s 32ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 448ms/step - loss: 0.6907 - auc_974: 0.5350\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 0.6908 - auc_974: 0.5487\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 451ms/step - loss: 0.6846 - auc_974: 0.5786\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 441ms/step - loss: 0.6875 - auc_974: 0.5842\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.6790 - auc_974: 0.6090\n",
      "13/13 [==============================] - 1s 32ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 438ms/step - loss: 0.6892 - auc_975: 0.5393\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 454ms/step - loss: 0.6889 - auc_975: 0.5492\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 442ms/step - loss: 0.6889 - auc_975: 0.5439\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 425ms/step - loss: 0.6898 - auc_975: 0.5622\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 439ms/step - loss: 0.6837 - auc_975: 0.5714\n",
      "13/13 [==============================] - 1s 32ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 483ms/step - loss: 0.6925 - auc_976: 0.5241\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 471ms/step - loss: 0.6960 - auc_976: 0.5192\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 472ms/step - loss: 0.6888 - auc_976: 0.5574\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 469ms/step - loss: 0.6885 - auc_976: 0.5628\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 472ms/step - loss: 0.6878 - auc_976: 0.5857\n",
      "13/13 [==============================] - 1s 36ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 463ms/step - loss: 0.6978 - auc_977: 0.4955\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 472ms/step - loss: 0.6933 - auc_977: 0.5233\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 492ms/step - loss: 0.6906 - auc_977: 0.5446\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 491ms/step - loss: 0.6897 - auc_977: 0.5593\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 0.6863 - auc_977: 0.5810\n",
      "13/13 [==============================] - 1s 34ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 471ms/step - loss: 0.6986 - auc_978: 0.4707\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 472ms/step - loss: 0.6913 - auc_978: 0.5373\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 478ms/step - loss: 0.6973 - auc_978: 0.5379\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 474ms/step - loss: 0.6876 - auc_978: 0.5507\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 485ms/step - loss: 0.6883 - auc_978: 0.5701\n",
      "13/13 [==============================] - 1s 42ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 542ms/step - loss: 0.6977 - auc_979: 0.5059\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 541ms/step - loss: 0.6900 - auc_979: 0.5461\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 554ms/step - loss: 0.6942 - auc_979: 0.5671\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 536ms/step - loss: 0.6868 - auc_979: 0.5634\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 552ms/step - loss: 0.6847 - auc_979: 0.5960\n",
      "13/13 [==============================] - 1s 42ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 544ms/step - loss: 0.6992 - auc_980: 0.5074\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 540ms/step - loss: 0.7123 - auc_980: 0.5247\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 532ms/step - loss: 0.6952 - auc_980: 0.5064\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 531ms/step - loss: 0.6923 - auc_980: 0.5494\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 533ms/step - loss: 0.6912 - auc_980: 0.5442\n",
      "13/13 [==============================] - 1s 42ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 545ms/step - loss: 0.7009 - auc_981: 0.4778\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 533ms/step - loss: 0.6868 - auc_981: 0.5608\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 532ms/step - loss: 0.6906 - auc_981: 0.5350\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 521ms/step - loss: 0.6870 - auc_981: 0.5571\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 558ms/step - loss: 0.6843 - auc_981: 0.5689\n",
      "13/13 [==============================] - 1s 38ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 635ms/step - loss: 0.6986 - auc_982: 0.5110\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 627ms/step - loss: 0.7019 - auc_982: 0.5359\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 638ms/step - loss: 0.6917 - auc_982: 0.5662\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 636ms/step - loss: 0.6900 - auc_982: 0.5588\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 634ms/step - loss: 0.6887 - auc_982: 0.5776\n",
      "13/13 [==============================] - 1s 42ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 630ms/step - loss: 0.6949 - auc_983: 0.5010\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 622ms/step - loss: 0.6890 - auc_983: 0.5626\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 637ms/step - loss: 0.6950 - auc_983: 0.5160\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 618ms/step - loss: 0.6892 - auc_983: 0.5572\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 622ms/step - loss: 0.6908 - auc_983: 0.5453\n",
      "13/13 [==============================] - 1s 42ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 613ms/step - loss: 0.6939 - auc_984: 0.4942\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 615ms/step - loss: 0.6875 - auc_984: 0.5551\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 649ms/step - loss: 0.6886 - auc_984: 0.5627\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 614ms/step - loss: 0.6902 - auc_984: 0.5562\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 627ms/step - loss: 0.6883 - auc_984: 0.5629\n",
      "13/13 [==============================] - 1s 40ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 688ms/step - loss: 0.6965 - auc_985: 0.5056\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 691ms/step - loss: 0.6971 - auc_985: 0.5026\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 686ms/step - loss: 0.6905 - auc_985: 0.5439\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 698ms/step - loss: 0.6888 - auc_985: 0.5555\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 682ms/step - loss: 0.6860 - auc_985: 0.5691\n",
      "13/13 [==============================] - 2s 47ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 687ms/step - loss: 0.6977 - auc_986: 0.4844\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 702ms/step - loss: 0.6870 - auc_986: 0.5780\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 684ms/step - loss: 0.6857 - auc_986: 0.5722\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 700ms/step - loss: 0.6861 - auc_986: 0.5724\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 677ms/step - loss: 0.6910 - auc_986: 0.5819\n",
      "13/13 [==============================] - 1s 44ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 686ms/step - loss: 0.6955 - auc_987: 0.4933\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 705ms/step - loss: 0.6849 - auc_987: 0.5891\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 680ms/step - loss: 0.6890 - auc_987: 0.5494\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 688ms/step - loss: 0.6873 - auc_987: 0.5748\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 674ms/step - loss: 0.6829 - auc_987: 0.5780\n",
      "13/13 [==============================] - 1s 48ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 439ms/step - loss: 0.6924 - auc_988: 0.5270\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 0.6938 - auc_988: 0.5304\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 437ms/step - loss: 0.6898 - auc_988: 0.5588\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 433ms/step - loss: 0.6880 - auc_988: 0.5625\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 436ms/step - loss: 0.6863 - auc_988: 0.5742\n",
      "13/13 [==============================] - 1s 39ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 443ms/step - loss: 0.6991 - auc_989: 0.4912\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 435ms/step - loss: 0.6926 - auc_989: 0.5239\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 436ms/step - loss: 0.6913 - auc_989: 0.5385\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 433ms/step - loss: 0.6903 - auc_989: 0.5507\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 464ms/step - loss: 0.6870 - auc_989: 0.5639\n",
      "13/13 [==============================] - 1s 32ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 449ms/step - loss: 0.6971 - auc_990: 0.5114\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 455ms/step - loss: 0.6977 - auc_990: 0.5065\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 0.6858 - auc_990: 0.5713\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.6887 - auc_990: 0.5808\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.6857 - auc_990: 0.5740\n",
      "13/13 [==============================] - 1s 33ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 497ms/step - loss: 0.6970 - auc_991: 0.4963\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 472ms/step - loss: 0.6994 - auc_991: 0.5121\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 0.7020 - auc_991: 0.5018\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 472ms/step - loss: 0.6913 - auc_991: 0.5404\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 474ms/step - loss: 0.6960 - auc_991: 0.5421\n",
      "13/13 [==============================] - 1s 35ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 479ms/step - loss: 0.6926 - auc_992: 0.5313\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 480ms/step - loss: 0.6911 - auc_992: 0.5499\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 482ms/step - loss: 0.6898 - auc_992: 0.5579\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 475ms/step - loss: 0.6870 - auc_992: 0.5732\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 462ms/step - loss: 0.6869 - auc_992: 0.5732\n",
      "13/13 [==============================] - 1s 35ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 461ms/step - loss: 0.6902 - auc_993: 0.5423\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 479ms/step - loss: 0.6881 - auc_993: 0.5517\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 474ms/step - loss: 0.6882 - auc_993: 0.5578\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 469ms/step - loss: 0.6883 - auc_993: 0.5508\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 468ms/step - loss: 0.6830 - auc_993: 0.5717\n",
      "13/13 [==============================] - 1s 34ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 490ms/step - loss: 0.7033 - auc_994: 0.4859\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 0.6900 - auc_994: 0.5477\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 0.6893 - auc_994: 0.5517\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 0.6857 - auc_994: 0.5833\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 0.6818 - auc_994: 0.5977\n",
      "13/13 [==============================] - 1s 39ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 557ms/step - loss: 0.7048 - auc_995: 0.4847\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 577ms/step - loss: 0.6974 - auc_995: 0.5215\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 556ms/step - loss: 0.6948 - auc_995: 0.5204\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 0.6905 - auc_995: 0.5647\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 523ms/step - loss: 0.6890 - auc_995: 0.5709\n",
      "13/13 [==============================] - 1s 35ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 520ms/step - loss: 0.6900 - auc_996: 0.5401\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 0.6899 - auc_996: 0.5431\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 0.6886 - auc_996: 0.5483\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 0.6941 - auc_996: 0.5425\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 0.6878 - auc_996: 0.5623\n",
      "13/13 [==============================] - 1s 37ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 578ms/step - loss: 0.6971 - auc_997: 0.5101\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 577ms/step - loss: 0.6935 - auc_997: 0.5210\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 587ms/step - loss: 0.6883 - auc_997: 0.5664\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 568ms/step - loss: 0.6841 - auc_997: 0.5792\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 589ms/step - loss: 0.6912 - auc_997: 0.5668\n",
      "13/13 [==============================] - 1s 39ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 570ms/step - loss: 0.6965 - auc_998: 0.5059\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 575ms/step - loss: 0.6930 - auc_998: 0.5234\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 574ms/step - loss: 0.6923 - auc_998: 0.5464\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 569ms/step - loss: 0.6902 - auc_998: 0.5747\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 572ms/step - loss: 0.6858 - auc_998: 0.5722\n",
      "13/13 [==============================] - 1s 40ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 594ms/step - loss: 0.7023 - auc_999: 0.4898\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 579ms/step - loss: 0.6913 - auc_999: 0.5481\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 594ms/step - loss: 0.6889 - auc_999: 0.5381\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 582ms/step - loss: 0.6830 - auc_999: 0.5822\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 595ms/step - loss: 0.6865 - auc_999: 0.5631\n",
      "13/13 [==============================] - 1s 46ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 640ms/step - loss: 0.6963 - auc_1000: 0.4953\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 639ms/step - loss: 0.6901 - auc_1000: 0.5537\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 649ms/step - loss: 0.6890 - auc_1000: 0.5678\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 672ms/step - loss: 0.6881 - auc_1000: 0.5918\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 661ms/step - loss: 0.6870 - auc_1000: 0.5637\n",
      "13/13 [==============================] - 1s 39ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 635ms/step - loss: 0.6992 - auc_1001: 0.4885\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 652ms/step - loss: 0.6899 - auc_1001: 0.5432\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 681ms/step - loss: 0.6906 - auc_1001: 0.5590\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 651ms/step - loss: 0.6863 - auc_1001: 0.5645\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 646ms/step - loss: 0.6860 - auc_1001: 0.5687\n",
      "13/13 [==============================] - 1s 42ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 646ms/step - loss: 0.6954 - auc_1002: 0.5135\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 632ms/step - loss: 0.7056 - auc_1002: 0.5018\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 637ms/step - loss: 0.6897 - auc_1002: 0.5396\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 632ms/step - loss: 0.6868 - auc_1002: 0.5663\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 637ms/step - loss: 0.6892 - auc_1002: 0.5544\n",
      "13/13 [==============================] - 1s 49ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 12s 713ms/step - loss: 0.6952 - auc_1003: 0.5161\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 730ms/step - loss: 0.7045 - auc_1003: 0.5424\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 738ms/step - loss: 0.6999 - auc_1003: 0.5348\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 723ms/step - loss: 0.6882 - auc_1003: 0.5711\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 730ms/step - loss: 0.6880 - auc_1003: 0.5681\n",
      "13/13 [==============================] - 1s 47ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 719ms/step - loss: 0.6954 - auc_1004: 0.5080\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 715ms/step - loss: 0.6944 - auc_1004: 0.5460\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 719ms/step - loss: 0.6886 - auc_1004: 0.5729\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 732ms/step - loss: 0.6926 - auc_1004: 0.5361\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 780ms/step - loss: 0.6855 - auc_1004: 0.5776\n",
      "13/13 [==============================] - 2s 52ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 13s 723ms/step - loss: 0.6996 - auc_1005: 0.4912\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 749ms/step - loss: 0.6920 - auc_1005: 0.5426\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 727ms/step - loss: 0.6934 - auc_1005: 0.5570\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 716ms/step - loss: 0.6883 - auc_1005: 0.5535\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 758ms/step - loss: 0.6870 - auc_1005: 0.5591\n",
      "13/13 [==============================] - 1s 48ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 763ms/step - loss: 0.6965 - auc_1006: 0.4888\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 776ms/step - loss: 0.6922 - auc_1006: 0.5530\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 6s 789ms/step - loss: 0.6914 - auc_1006: 0.5612\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 6s 802ms/step - loss: 0.6923 - auc_1006: 0.5759\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 6s 796ms/step - loss: 0.6861 - auc_1006: 0.5732\n",
      "13/13 [==============================] - 1s 49ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 802ms/step - loss: 0.6957 - auc_1007: 0.5017\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 6s 777ms/step - loss: 0.7007 - auc_1007: 0.4849\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 763ms/step - loss: 0.6879 - auc_1007: 0.5770\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 6s 789ms/step - loss: 0.6828 - auc_1007: 0.6057\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 747ms/step - loss: 0.6895 - auc_1007: 0.5514\n",
      "13/13 [==============================] - 1s 47ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 12s 765ms/step - loss: 0.6993 - auc_1008: 0.4946\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 6s 797ms/step - loss: 0.6901 - auc_1008: 0.5399\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 751ms/step - loss: 0.6881 - auc_1008: 0.5612\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 760ms/step - loss: 0.6893 - auc_1008: 0.5404\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 6s 805ms/step - loss: 0.6884 - auc_1008: 0.5525\n",
      "13/13 [==============================] - 1s 50ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 497ms/step - loss: 0.6957 - auc_1009: 0.5211\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 485ms/step - loss: 0.7027 - auc_1009: 0.5200\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 0.6909 - auc_1009: 0.5460\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 486ms/step - loss: 0.6870 - auc_1009: 0.5726\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 485ms/step - loss: 0.6843 - auc_1009: 0.5891\n",
      "13/13 [==============================] - 1s 35ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 504ms/step - loss: 0.6937 - auc_1010: 0.5121\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 494ms/step - loss: 0.6893 - auc_1010: 0.5564\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 504ms/step - loss: 0.6908 - auc_1010: 0.5558\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 0.6853 - auc_1010: 0.5809\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 503ms/step - loss: 0.6906 - auc_1010: 0.5611\n",
      "13/13 [==============================] - 1s 35ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 493ms/step - loss: 0.6941 - auc_1011: 0.5493\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 485ms/step - loss: 0.7039 - auc_1011: 0.5320\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 497ms/step - loss: 0.6917 - auc_1011: 0.5228\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 0.6899 - auc_1011: 0.5357\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 0.6879 - auc_1011: 0.5513\n",
      "13/13 [==============================] - 1s 35ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 514ms/step - loss: 0.6945 - auc_1012: 0.5195\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 543ms/step - loss: 0.6910 - auc_1012: 0.5482\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 534ms/step - loss: 0.6908 - auc_1012: 0.5570\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 541ms/step - loss: 0.6857 - auc_1012: 0.5804\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 526ms/step - loss: 0.6866 - auc_1012: 0.5714\n",
      "13/13 [==============================] - 1s 36ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 531ms/step - loss: 0.6961 - auc_1013: 0.5077\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 526ms/step - loss: 0.6892 - auc_1013: 0.5499\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 547ms/step - loss: 0.6856 - auc_1013: 0.5733\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 525ms/step - loss: 0.6839 - auc_1013: 0.5763\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 541ms/step - loss: 0.6869 - auc_1013: 0.5703\n",
      "13/13 [==============================] - 1s 34ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 528ms/step - loss: 0.6948 - auc_1014: 0.5094\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 524ms/step - loss: 0.6925 - auc_1014: 0.5384\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 535ms/step - loss: 0.6860 - auc_1014: 0.5630\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 520ms/step - loss: 0.6849 - auc_1014: 0.5675\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 528ms/step - loss: 0.6827 - auc_1014: 0.5797\n",
      "13/13 [==============================] - 1s 39ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 562ms/step - loss: 0.7016 - auc_1015: 0.4889\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 586ms/step - loss: 0.6911 - auc_1015: 0.5489\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 590ms/step - loss: 0.6904 - auc_1015: 0.5485\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 573ms/step - loss: 0.6899 - auc_1015: 0.5485\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 579ms/step - loss: 0.6873 - auc_1015: 0.5699\n",
      "13/13 [==============================] - 1s 38ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 566ms/step - loss: 0.6952 - auc_1016: 0.5189\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 564ms/step - loss: 0.6974 - auc_1016: 0.5217\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 586ms/step - loss: 0.6983 - auc_1016: 0.5043\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 563ms/step - loss: 0.6881 - auc_1016: 0.5701\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 558ms/step - loss: 0.6898 - auc_1016: 0.5613\n",
      "13/13 [==============================] - 1s 39ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 575ms/step - loss: 0.6934 - auc_1017: 0.5203\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 574ms/step - loss: 0.7019 - auc_1017: 0.5248\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 562ms/step - loss: 0.6864 - auc_1017: 0.5603\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 556ms/step - loss: 0.6874 - auc_1017: 0.5799\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 587ms/step - loss: 0.6815 - auc_1017: 0.5858\n",
      "13/13 [==============================] - 1s 38ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 635ms/step - loss: 0.6984 - auc_1018: 0.5075\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 629ms/step - loss: 0.6893 - auc_1018: 0.5507\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 659ms/step - loss: 0.6914 - auc_1018: 0.5503\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 620ms/step - loss: 0.6857 - auc_1018: 0.5840\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 655ms/step - loss: 0.6882 - auc_1018: 0.5711\n",
      "13/13 [==============================] - 1s 42ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 646ms/step - loss: 0.7027 - auc_1019: 0.5038\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 621ms/step - loss: 0.6980 - auc_1019: 0.5021\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 639ms/step - loss: 0.6903 - auc_1019: 0.5445\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 612ms/step - loss: 0.6897 - auc_1019: 0.5726\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 652ms/step - loss: 0.6900 - auc_1019: 0.5660\n",
      "13/13 [==============================] - 1s 42ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 632ms/step - loss: 0.6917 - auc_1020: 0.5347\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 624ms/step - loss: 0.6875 - auc_1020: 0.5578\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 645ms/step - loss: 0.6916 - auc_1020: 0.5340\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 616ms/step - loss: 0.7028 - auc_1020: 0.5468\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 644ms/step - loss: 0.6911 - auc_1020: 0.5624\n",
      "13/13 [==============================] - 1s 44ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 12s 751ms/step - loss: 0.6961 - auc_1021: 0.5083\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 699ms/step - loss: 0.6915 - auc_1021: 0.5458\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 696ms/step - loss: 0.6861 - auc_1021: 0.5740\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 732ms/step - loss: 0.6830 - auc_1021: 0.5889\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 712ms/step - loss: 0.6858 - auc_1021: 0.5735\n",
      "13/13 [==============================] - 1s 45ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 709ms/step - loss: 0.6977 - auc_1022: 0.5054\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 696ms/step - loss: 0.7014 - auc_1022: 0.5674\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 734ms/step - loss: 0.7020 - auc_1022: 0.5351\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 722ms/step - loss: 0.6911 - auc_1022: 0.5428\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 718ms/step - loss: 0.6940 - auc_1022: 0.5333\n",
      "13/13 [==============================] - 1s 45ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 712ms/step - loss: 0.6937 - auc_1023: 0.5198\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 697ms/step - loss: 0.6879 - auc_1023: 0.5577\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 706ms/step - loss: 0.6932 - auc_1023: 0.5218\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 701ms/step - loss: 0.6819 - auc_1023: 0.5891\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 717ms/step - loss: 0.6887 - auc_1023: 0.5590\n",
      "13/13 [==============================] - 1s 43ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 802ms/step - loss: 0.6953 - auc_1024: 0.5359\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 740ms/step - loss: 0.7159 - auc_1024: 0.5547\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 6s 800ms/step - loss: 0.6971 - auc_1024: 0.5363\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 726ms/step - loss: 0.6912 - auc_1024: 0.5563\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 763ms/step - loss: 0.6870 - auc_1024: 0.5787\n",
      "13/13 [==============================] - 1s 51ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 13s 819ms/step - loss: 0.7088 - auc_1025: 0.4706\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 6s 801ms/step - loss: 0.6935 - auc_1025: 0.5354\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 747ms/step - loss: 0.6902 - auc_1025: 0.5548\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 6s 785ms/step - loss: 0.6882 - auc_1025: 0.5807\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 737ms/step - loss: 0.6902 - auc_1025: 0.5652\n",
      "13/13 [==============================] - 1s 49ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 741ms/step - loss: 0.7064 - auc_1026: 0.4862\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 782ms/step - loss: 0.6904 - auc_1026: 0.5267\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 724ms/step - loss: 0.6876 - auc_1026: 0.5683\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 740ms/step - loss: 0.6974 - auc_1026: 0.5590\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 743ms/step - loss: 0.6886 - auc_1026: 0.5449\n",
      "13/13 [==============================] - 1s 59ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 12s 838ms/step - loss: 0.7031 - auc_1027: 0.5203\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 6s 846ms/step - loss: 0.6944 - auc_1027: 0.5434\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 6s 870ms/step - loss: 0.6906 - auc_1027: 0.5440\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 6s 847ms/step - loss: 0.6903 - auc_1027: 0.5722\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 6s 862ms/step - loss: 0.6904 - auc_1027: 0.5681\n",
      "13/13 [==============================] - 1s 46ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 12s 846ms/step - loss: 0.6998 - auc_1028: 0.5131\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 6s 842ms/step - loss: 0.6929 - auc_1028: 0.5275\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 6s 846ms/step - loss: 0.6903 - auc_1028: 0.5379\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 6s 878ms/step - loss: 0.6896 - auc_1028: 0.5521\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 6s 842ms/step - loss: 0.6953 - auc_1028: 0.5443\n",
      "13/13 [==============================] - 1s 53ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 12s 859ms/step - loss: 0.6953 - auc_1029: 0.5172\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 6s 824ms/step - loss: 0.6890 - auc_1029: 0.5522\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 6s 850ms/step - loss: 0.6883 - auc_1029: 0.5445\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 6s 841ms/step - loss: 0.6828 - auc_1029: 0.5760\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 6s 851ms/step - loss: 0.6847 - auc_1029: 0.5722\n",
      "13/13 [==============================] - 1s 52ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 590ms/step - loss: 0.6964 - auc_1030: 0.5288\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 579ms/step - loss: 0.6968 - auc_1030: 0.5162\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 577ms/step - loss: 0.6875 - auc_1030: 0.5688\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 570ms/step - loss: 0.6872 - auc_1030: 0.5809\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 588ms/step - loss: 0.6861 - auc_1030: 0.5848\n",
      "13/13 [==============================] - 1s 40ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 564ms/step - loss: 0.6983 - auc_1031: 0.5129\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 585ms/step - loss: 0.6960 - auc_1031: 0.5194\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 585ms/step - loss: 0.6875 - auc_1031: 0.5740\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 580ms/step - loss: 0.6927 - auc_1031: 0.5538\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 587ms/step - loss: 0.6862 - auc_1031: 0.5768\n",
      "13/13 [==============================] - 1s 47ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 581ms/step - loss: 0.7015 - auc_1032: 0.4954\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 585ms/step - loss: 0.6913 - auc_1032: 0.5460\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 581ms/step - loss: 0.6889 - auc_1032: 0.5446\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 582ms/step - loss: 0.6866 - auc_1032: 0.5589\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 586ms/step - loss: 0.6863 - auc_1032: 0.5717\n",
      "13/13 [==============================] - 1s 41ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 614ms/step - loss: 0.7013 - auc_1033: 0.4938\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 599ms/step - loss: 0.6955 - auc_1033: 0.5412\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 633ms/step - loss: 0.6875 - auc_1033: 0.5616\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 629ms/step - loss: 0.6901 - auc_1033: 0.5673\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 629ms/step - loss: 0.6842 - auc_1033: 0.5872\n",
      "13/13 [==============================] - 1s 40ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 624ms/step - loss: 0.7097 - auc_1034: 0.5299\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 613ms/step - loss: 0.6888 - auc_1034: 0.5605\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 636ms/step - loss: 0.6996 - auc_1034: 0.5267\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 603ms/step - loss: 0.7031 - auc_1034: 0.5301\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 645ms/step - loss: 0.6899 - auc_1034: 0.5473\n",
      "13/13 [==============================] - 1s 40ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 631ms/step - loss: 0.7039 - auc_1035: 0.4726\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 627ms/step - loss: 0.6932 - auc_1035: 0.5140\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 638ms/step - loss: 0.6906 - auc_1035: 0.5319\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 595ms/step - loss: 0.6857 - auc_1035: 0.5709\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 624ms/step - loss: 0.6835 - auc_1035: 0.5860\n",
      "13/13 [==============================] - 1s 42ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 10s 657ms/step - loss: 0.7008 - auc_1036: 0.5197\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 649ms/step - loss: 0.6944 - auc_1036: 0.5192\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 639ms/step - loss: 0.6960 - auc_1036: 0.5119\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 654ms/step - loss: 0.6980 - auc_1036: 0.4905\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 656ms/step - loss: 0.6900 - auc_1036: 0.5672\n",
      "13/13 [==============================] - 1s 52ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 690ms/step - loss: 0.6969 - auc_1037: 0.5104\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 679ms/step - loss: 0.6953 - auc_1037: 0.5509\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 689ms/step - loss: 0.6984 - auc_1037: 0.5330\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 6s 797ms/step - loss: 0.6872 - auc_1037: 0.5801\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 6s 785ms/step - loss: 0.6882 - auc_1037: 0.5681\n",
      "13/13 [==============================] - 2s 45ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 676ms/step - loss: 0.7041 - auc_1038: 0.5029\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 669ms/step - loss: 0.6949 - auc_1038: 0.5194\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 690ms/step - loss: 0.6858 - auc_1038: 0.5670\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 684ms/step - loss: 0.6859 - auc_1038: 0.5822\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 677ms/step - loss: 0.6835 - auc_1038: 0.5811\n",
      "13/13 [==============================] - 1s 46ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 13s 798ms/step - loss: 0.7059 - auc_1039: 0.5093\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 760ms/step - loss: 0.6982 - auc_1039: 0.5221\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 764ms/step - loss: 0.7000 - auc_1039: 0.5503\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 748ms/step - loss: 0.6889 - auc_1039: 0.5579\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 757ms/step - loss: 0.6884 - auc_1039: 0.5836\n",
      "13/13 [==============================] - 2s 63ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 764ms/step - loss: 0.7040 - auc_1040: 0.4755\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 725ms/step - loss: 0.6966 - auc_1040: 0.5314\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 747ms/step - loss: 0.6901 - auc_1040: 0.5646\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 773ms/step - loss: 0.6869 - auc_1040: 0.5689\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 762ms/step - loss: 0.6920 - auc_1040: 0.5672\n",
      "13/13 [==============================] - 1s 53ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 12s 760ms/step - loss: 0.6950 - auc_1041: 0.5007\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 6s 776ms/step - loss: 0.7003 - auc_1041: 0.5524\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 736ms/step - loss: 0.7022 - auc_1041: 0.5370\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 775ms/step - loss: 0.6913 - auc_1041: 0.5262\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 744ms/step - loss: 0.6945 - auc_1041: 0.5417\n",
      "13/13 [==============================] - 1s 47ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 12s 813ms/step - loss: 0.7115 - auc_1042: 0.4801\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 6s 822ms/step - loss: 0.6931 - auc_1042: 0.5529\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 6s 780ms/step - loss: 0.6953 - auc_1042: 0.5302\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 6s 853ms/step - loss: 0.6956 - auc_1042: 0.5258\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 6s 825ms/step - loss: 0.6900 - auc_1042: 0.5532\n",
      "13/13 [==============================] - 1s 52ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 14s 909ms/step - loss: 0.6996 - auc_1043: 0.5134\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 6s 859ms/step - loss: 0.6903 - auc_1043: 0.5448\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 6s 888ms/step - loss: 0.6907 - auc_1043: 0.5549\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 6s 817ms/step - loss: 0.6850 - auc_1043: 0.5754\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 6s 833ms/step - loss: 0.6853 - auc_1043: 0.5710\n",
      "13/13 [==============================] - 1s 58ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 12s 843ms/step - loss: 0.7176 - auc_1044: 0.4812\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 6s 835ms/step - loss: 0.6876 - auc_1044: 0.5515\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 6s 829ms/step - loss: 0.6887 - auc_1044: 0.5495\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 6s 834ms/step - loss: 0.6855 - auc_1044: 0.5607\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 6s 801ms/step - loss: 0.6862 - auc_1044: 0.5652\n",
      "13/13 [==============================] - 1s 60ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 13s 999ms/step - loss: 0.7076 - auc_1045: 0.4885\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.6938 - auc_1045: 0.5189\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.6908 - auc_1045: 0.5503\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 7s 988ms/step - loss: 0.6853 - auc_1045: 0.6038\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.6877 - auc_1045: 0.5750\n",
      "13/13 [==============================] - 2s 64ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 13s 990ms/step - loss: 0.7118 - auc_1046: 0.5115\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.7093 - auc_1046: 0.5066\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 7s 999ms/step - loss: 0.6909 - auc_1046: 0.5665\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.6897 - auc_1046: 0.5529\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 7s 996ms/step - loss: 0.6911 - auc_1046: 0.5697\n",
      "13/13 [==============================] - 2s 58ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 13s 978ms/step - loss: 0.7014 - auc_1047: 0.4521\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.6902 - auc_1047: 0.5287\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 7s 984ms/step - loss: 0.6847 - auc_1047: 0.5675\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 7s 971ms/step - loss: 0.6882 - auc_1047: 0.5595\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.6868 - auc_1047: 0.5678\n",
      "13/13 [==============================] - 2s 64ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 14s 1s/step - loss: 0.6965 - auc_1048: 0.5214\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.6981 - auc_1048: 0.5127\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.6932 - auc_1048: 0.5274\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.6874 - auc_1048: 0.5660\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.6866 - auc_1048: 0.5771\n",
      "13/13 [==============================] - 2s 56ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 14s 1s/step - loss: 0.6989 - auc_1049: 0.5266\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.6995 - auc_1049: 0.5179\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.6900 - auc_1049: 0.5505\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.6931 - auc_1049: 0.5554\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.6944 - auc_1049: 0.5428\n",
      "13/13 [==============================] - 1s 57ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 13s 1s/step - loss: 0.6943 - auc_1050: 0.5380\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.7053 - auc_1050: 0.4825\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.6898 - auc_1050: 0.5780\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.6886 - auc_1050: 0.5657\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.6870 - auc_1050: 0.5693\n",
      "13/13 [==============================] - 1s 59ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 698ms/step - loss: 0.6995 - auc_1051: 0.4996\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 709ms/step - loss: 0.6965 - auc_1051: 0.5710\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 713ms/step - loss: 0.6960 - auc_1051: 0.5486\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 707ms/step - loss: 0.6925 - auc_1051: 0.5392\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 683ms/step - loss: 0.6860 - auc_1051: 0.6014\n",
      "13/13 [==============================] - 1s 44ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 12s 687ms/step - loss: 0.7019 - auc_1052: 0.5075\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 702ms/step - loss: 0.6975 - auc_1052: 0.5101\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 716ms/step - loss: 0.6934 - auc_1052: 0.5496\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 688ms/step - loss: 0.6919 - auc_1052: 0.5608\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 716ms/step - loss: 0.6931 - auc_1052: 0.5577\n",
      "13/13 [==============================] - 1s 41ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 693ms/step - loss: 0.6978 - auc_1053: 0.5232\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 732ms/step - loss: 0.6986 - auc_1053: 0.5150\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 684ms/step - loss: 0.6879 - auc_1053: 0.5551\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 695ms/step - loss: 0.6874 - auc_1053: 0.5618\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 691ms/step - loss: 0.6855 - auc_1053: 0.5732\n",
      "13/13 [==============================] - 1s 42ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 721ms/step - loss: 0.6946 - auc_1054: 0.5368\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 724ms/step - loss: 0.7215 - auc_1054: 0.5577\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 755ms/step - loss: 0.6969 - auc_1054: 0.5585\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 746ms/step - loss: 0.6967 - auc_1054: 0.4999\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 746ms/step - loss: 0.6868 - auc_1054: 0.5833\n",
      "13/13 [==============================] - 1s 43ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 734ms/step - loss: 0.7013 - auc_1055: 0.5007\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 741ms/step - loss: 0.6917 - auc_1055: 0.5447\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 744ms/step - loss: 0.6873 - auc_1055: 0.5717\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 735ms/step - loss: 0.6880 - auc_1055: 0.5597\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 714ms/step - loss: 0.6844 - auc_1055: 0.5782\n",
      "13/13 [==============================] - 1s 43ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 12s 745ms/step - loss: 0.6971 - auc_1056: 0.5041\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 721ms/step - loss: 0.6912 - auc_1056: 0.5413\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 727ms/step - loss: 0.6935 - auc_1056: 0.5562\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 737ms/step - loss: 0.6923 - auc_1056: 0.5544\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 735ms/step - loss: 0.6869 - auc_1056: 0.5696\n",
      "13/13 [==============================] - 1s 42ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 13s 800ms/step - loss: 0.6973 - auc_1057: 0.5055\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 642ms/step - loss: 0.6851 - auc_1057: 0.5795\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.6847 - auc_1057: 0.5859\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 6s 802ms/step - loss: 0.6836 - auc_1057: 0.5767\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 6s 814ms/step - loss: 0.6850 - auc_1057: 0.5811\n",
      "13/13 [==============================] - 2s 53ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 13s 804ms/step - loss: 0.7046 - auc_1058: 0.4888\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 6s 801ms/step - loss: 0.6882 - auc_1058: 0.5810\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 6s 797ms/step - loss: 0.6901 - auc_1058: 0.5480\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 6s 774ms/step - loss: 0.6912 - auc_1058: 0.5510\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 747ms/step - loss: 0.6859 - auc_1058: 0.5778\n",
      "13/13 [==============================] - 2s 47ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 13s 790ms/step - loss: 0.6937 - auc_1059: 0.5217\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 6s 790ms/step - loss: 0.6897 - auc_1059: 0.5397\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 769ms/step - loss: 0.6848 - auc_1059: 0.5798\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 768ms/step - loss: 0.6830 - auc_1059: 0.5750\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 6s 800ms/step - loss: 0.6869 - auc_1059: 0.5713\n",
      "13/13 [==============================] - 1s 42ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 339s 455ms/step - loss: 0.7108 - auc_1060: 0.4974\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.6932 - auc_1060: 0.5179\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 3s 415ms/step - loss: 0.6881 - auc_1060: 0.5561\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 3s 400ms/step - loss: 0.6869 - auc_1060: 0.5875\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 3s 407ms/step - loss: 0.6984 - auc_1060: 0.5653\n",
      "13/13 [==============================] - 1s 26ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 400ms/step - loss: 0.7081 - auc_1061: 0.5009\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 3s 415ms/step - loss: 0.6923 - auc_1061: 0.5462\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 590ms/step - loss: 0.6918 - auc_1061: 0.5487\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 612ms/step - loss: 0.6872 - auc_1061: 0.5666\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 613ms/step - loss: 0.6953 - auc_1061: 0.5496\n",
      "13/13 [==============================] - 1s 36ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 9s 608ms/step - loss: 0.6993 - auc_1062: 0.5177\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 4s 599ms/step - loss: 0.6968 - auc_1062: 0.5492\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 600ms/step - loss: 0.6928 - auc_1062: 0.5517\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 588ms/step - loss: 0.6865 - auc_1062: 0.5702\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 590ms/step - loss: 0.6864 - auc_1062: 0.5699\n",
      "13/13 [==============================] - 1s 35ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 35272s 219s/step - loss: 0.6948 - auc_1063: 0.5323\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 6s 786ms/step - loss: 0.6930 - auc_1063: 0.5688\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 4s 564ms/step - loss: 0.6942 - auc_1063: 0.5594\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 4s 540ms/step - loss: 0.6872 - auc_1063: 0.5780\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 4s 499ms/step - loss: 0.6844 - auc_1063: 0.5895\n",
      "13/13 [==============================] - 2s 38ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 645ms/step - loss: 0.6958 - auc_1064: 0.5278\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 727ms/step - loss: 0.6976 - auc_1064: 0.5302\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 5s 661ms/step - loss: 0.6879 - auc_1064: 0.5600\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 5s 645ms/step - loss: 0.6905 - auc_1064: 0.5568\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 5s 642ms/step - loss: 0.6843 - auc_1064: 0.5803\n",
      "13/13 [==============================] - 1s 39ms/step\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 11s 670ms/step - loss: 0.6992 - auc_1065: 0.4934\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 5s 747ms/step - loss: 0.6948 - auc_1065: 0.5091\n",
      "Epoch 3/5\n",
      "1/7 [===>..........................] - ETA: 4s - loss: 0.6961 - auc_1065: 0.4894"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[266], line 59\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39m# Create GridSearchCV object\u001b[39;00m\n\u001b[0;32m     58\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mKerasGridSearchWrapper(), param_grid\u001b[39m=\u001b[39mparam_grid, scoring\u001b[39m=\u001b[39mscoring, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m---> 59\u001b[0m grid_result \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     61\u001b[0m \u001b[39m# Display results\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m using \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (grid_result\u001b[39m.\u001b[39mbest_score_, grid_result\u001b[39m.\u001b[39mbest_params_))\n",
      "File \u001b[1;32mc:\\Users\\sofia\\Downloads\\BTT\\final_project\\venv\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sofia\\Downloads\\BTT\\final_project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sofia\\Downloads\\BTT\\final_project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\sofia\\Downloads\\BTT\\final_project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sofia\\Downloads\\BTT\\final_project\\venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\sofia\\Downloads\\BTT\\final_project\\venv\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\sofia\\Downloads\\BTT\\final_project\\venv\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\sofia\\Downloads\\BTT\\final_project\\venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sofia\\Downloads\\BTT\\final_project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    730\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 732\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    734\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    735\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "Cell \u001b[1;32mIn[266], line 41\u001b[0m, in \u001b[0;36mKerasGridSearchWrapper.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[0;32m     40\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m build_clf(learning_rate1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearning_rate1, units1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits1, units2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits2)\n\u001b[1;32m---> 41\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(X, y, epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m)\n\u001b[0;32m     42\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\sofia\\Downloads\\BTT\\final_project\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\sofia\\Downloads\\BTT\\final_project\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\sofia\\Downloads\\BTT\\final_project\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\sofia\\Downloads\\BTT\\final_project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\sofia\\Downloads\\BTT\\final_project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\sofia\\Downloads\\BTT\\final_project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\sofia\\Downloads\\BTT\\final_project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\sofia\\Downloads\\BTT\\final_project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Users\\sofia\\Downloads\\BTT\\final_project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\sofia\\Downloads\\BTT\\final_project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.base import BaseEstimator\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.initializers import Constant\n",
    "from keras.metrics import AUC\n",
    "\n",
    "# Define your build_clf function\n",
    "def build_clf(learning_rate1, units1, units2):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add an embedding layer\n",
    "    embedding_layer = Embedding(input_dim=num_words, output_dim=EMBEDDING_DIM,\n",
    "                                embeddings_initializer=Constant(embedding_matrix),\n",
    "                                input_length=100, trainable=False)\n",
    "    model.add(embedding_layer)\n",
    "    \n",
    "    # Add two LSTM layers with the specified number of units\n",
    "    model.add(LSTM(units=units1, dropout=.4, recurrent_dropout=.4, return_sequences=True))\n",
    "    model.add(LSTM(units=units2, dropout=.2, recurrent_dropout=.4))\n",
    "    \n",
    "    # Add a dense output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer_func = keras.optimizers.Adam(learning_rate = learning_rate1)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer_func, metrics=[AUC()])\n",
    "    return model\n",
    "\n",
    "# Define a wrapper class for Keras model to work with GridSearchCV because the keras.wrapper.gridsearch wasn't importing for the life of me...\n",
    "class KerasGridSearchWrapper(BaseEstimator):\n",
    "    def __init__(self, learning_rate1 = .001, units1 = 16, units2 = 16):\n",
    "        self.learning_rate1 = learning_rate1\n",
    "        self.units1 = units1\n",
    "        self.units2 = units2\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model = build_clf(learning_rate1 = self.learning_rate1, units1 = self.units1, units2 = self.units2)\n",
    "        self.model.fit(X, y, epochs=5, batch_size=128)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# Define hyperparameter grid I kept changing this\n",
    "param_grid = {\n",
    "    \"learning_rate1\": np.arange(.001, .011, .005),\n",
    "    \"units1\": np.arange(16,128,16),\n",
    "    \"units2\":np.arange(16,128,16)\n",
    "}\n",
    "\n",
    "# Create scoring metric\n",
    "scoring = make_scorer(roc_auc_score)\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=KerasGridSearchWrapper(), param_grid=param_grid, scoring=scoring, cv=3)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Display results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Creating the Final Model </h1>\n",
    "<h3>Why I chose the Layer Type </h3>\n",
    "The LSTM is more complex than GRU because it has more gates and a memory cell that can better contextualize words in a document in long range dependencies\n",
    "<h3>Why I Chose the AUC Metric</h3>\n",
    "Because this model can be used for a recommender system, its worse to have a false positive than a false negative because you dont want to recommend a book thats disliked by readers. Because of that I ruled out recall. AUC is the amount of true positives over false positives, AUC also takes into account the probability that each prediction will be right so I chose AUC as my metric seems to be better for classifying text data than precision is.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 100)          1871100   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100, 16)           7488      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               74240     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1952957 (7.45 MB)\n",
      "Trainable params: 81857 (319.75 KB)\n",
      "Non-trainable params: 1871100 (7.14 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(num_words, EMBEDDING_DIM, \n",
    "                           embeddings_initializer = Constant(embedding_matrix),\n",
    "                           input_length = 100,\n",
    "                           trainable = False)\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(units=16, dropout = .40, recurrent_dropout = .40, return_sequences = True))\n",
    "\n",
    "model.add(LSTM(units=128, dropout = .20, recurrent_dropout = .40))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "optimizer_func = keras.optimizers.Adam(learning_rate=.001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer_func, metrics=[AUC()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theres a lot less trainable params than total params because I created  the word embeddings dictionary\n",
    "myself so in theory this will make it all train faster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training process\n",
      "Epoch 1/50\n",
      "538/538 - 181s - loss: 0.5427 - auc: 0.8012 - val_loss: 0.4921 - val_auc: 0.8464 - lr: 0.0010 - 181s/epoch - 336ms/step\n",
      "Epoch 2/50\n",
      "538/538 - 183s - loss: 0.4935 - auc: 0.8413 - val_loss: 0.4625 - val_auc: 0.8628 - lr: 0.0010 - 183s/epoch - 340ms/step\n",
      "Epoch 3/50\n",
      "538/538 - 190s - loss: 0.4731 - auc: 0.8552 - val_loss: 0.4569 - val_auc: 0.8683 - lr: 0.0010 - 190s/epoch - 353ms/step\n",
      "Epoch 4/50\n",
      "538/538 - 178s - loss: 0.4618 - auc: 0.8626 - val_loss: 0.4492 - val_auc: 0.8735 - lr: 0.0010 - 178s/epoch - 331ms/step\n",
      "Epoch 5/50\n",
      "538/538 - 175s - loss: 0.4562 - auc: 0.8663 - val_loss: 0.4417 - val_auc: 0.8757 - lr: 0.0010 - 175s/epoch - 325ms/step\n",
      "Epoch 6/50\n",
      "538/538 - 180s - loss: 0.4502 - auc: 0.8698 - val_loss: 0.4344 - val_auc: 0.8802 - lr: 0.0010 - 180s/epoch - 334ms/step\n",
      "Epoch 7/50\n",
      "538/538 - 172s - loss: 0.4443 - auc: 0.8734 - val_loss: 0.4354 - val_auc: 0.8826 - lr: 0.0010 - 172s/epoch - 319ms/step\n",
      "Epoch 8/50\n",
      "538/538 - 172s - loss: 0.4386 - auc: 0.8767 - val_loss: 0.4369 - val_auc: 0.8848 - lr: 0.0010 - 172s/epoch - 320ms/step\n",
      "Epoch 9/50\n",
      "538/538 - 173s - loss: 0.4329 - auc: 0.8803 - val_loss: 0.4257 - val_auc: 0.8848 - lr: 0.0010 - 173s/epoch - 322ms/step\n",
      "Epoch 10/50\n",
      "538/538 - 174s - loss: 0.4291 - auc: 0.8825 - val_loss: 0.4242 - val_auc: 0.8875 - lr: 0.0010 - 174s/epoch - 324ms/step\n",
      "Epoch 11/50\n",
      "538/538 - 172s - loss: 0.4252 - auc: 0.8848 - val_loss: 0.4230 - val_auc: 0.8874 - lr: 0.0010 - 172s/epoch - 319ms/step\n",
      "Epoch 12/50\n",
      "538/538 - 171s - loss: 0.4207 - auc: 0.8873 - val_loss: 0.4170 - val_auc: 0.8902 - lr: 0.0010 - 171s/epoch - 318ms/step\n",
      "Epoch 13/50\n",
      "538/538 - 170s - loss: 0.4198 - auc: 0.8878 - val_loss: 0.4176 - val_auc: 0.8916 - lr: 0.0010 - 170s/epoch - 315ms/step\n",
      "Epoch 14/50\n",
      "538/538 - 170s - loss: 0.4124 - auc: 0.8919 - val_loss: 0.4090 - val_auc: 0.8941 - lr: 0.0010 - 170s/epoch - 316ms/step\n",
      "Epoch 15/50\n",
      "538/538 - 170s - loss: 0.4108 - auc: 0.8926 - val_loss: 0.4047 - val_auc: 0.8960 - lr: 0.0010 - 170s/epoch - 316ms/step\n",
      "Epoch 16/50\n",
      "538/538 - 170s - loss: 0.4069 - auc: 0.8951 - val_loss: 0.4075 - val_auc: 0.8956 - lr: 0.0010 - 170s/epoch - 315ms/step\n",
      "Epoch 17/50\n",
      "538/538 - 170s - loss: 0.4016 - auc: 0.8979 - val_loss: 0.4065 - val_auc: 0.8987 - lr: 0.0010 - 170s/epoch - 317ms/step\n",
      "Epoch 18/50\n",
      "538/538 - 170s - loss: 0.3978 - auc: 0.9000 - val_loss: 0.4001 - val_auc: 0.8984 - lr: 0.0010 - 170s/epoch - 316ms/step\n",
      "Epoch 19/50\n",
      "538/538 - 171s - loss: 0.3963 - auc: 0.9006 - val_loss: 0.3933 - val_auc: 0.9022 - lr: 0.0010 - 171s/epoch - 317ms/step\n",
      "Epoch 20/50\n",
      "538/538 - 170s - loss: 0.3939 - auc: 0.9020 - val_loss: 0.3942 - val_auc: 0.9035 - lr: 0.0010 - 170s/epoch - 316ms/step\n",
      "Epoch 21/50\n",
      "538/538 - 171s - loss: 0.3905 - auc: 0.9036 - val_loss: 0.3878 - val_auc: 0.9054 - lr: 0.0010 - 171s/epoch - 317ms/step\n",
      "Epoch 22/50\n",
      "538/538 - 170s - loss: 0.3860 - auc: 0.9058 - val_loss: 0.3878 - val_auc: 0.9057 - lr: 0.0010 - 170s/epoch - 316ms/step\n",
      "Epoch 23/50\n",
      "538/538 - 172s - loss: 0.3859 - auc: 0.9061 - val_loss: 0.3812 - val_auc: 0.9085 - lr: 0.0010 - 172s/epoch - 319ms/step\n",
      "Epoch 24/50\n",
      "538/538 - 171s - loss: 0.3829 - auc: 0.9074 - val_loss: 0.3833 - val_auc: 0.9071 - lr: 0.0010 - 171s/epoch - 317ms/step\n",
      "Epoch 25/50\n",
      "538/538 - 170s - loss: 0.3787 - auc: 0.9093 - val_loss: 0.3929 - val_auc: 0.9051 - lr: 0.0010 - 170s/epoch - 316ms/step\n",
      "Epoch 26/50\n",
      "538/538 - 171s - loss: 0.3739 - auc: 0.9121 - val_loss: 0.3831 - val_auc: 0.9085 - lr: 0.0010 - 171s/epoch - 317ms/step\n",
      "Epoch 27/50\n",
      "538/538 - 171s - loss: 0.3780 - auc: 0.9103 - val_loss: 0.3734 - val_auc: 0.9130 - lr: 0.0010 - 171s/epoch - 317ms/step\n",
      "Epoch 28/50\n",
      "538/538 - 32684s - loss: 0.3718 - auc: 0.9132 - val_loss: 0.3698 - val_auc: 0.9143 - lr: 0.0010 - 32684s/epoch - 61s/step\n",
      "Epoch 29/50\n",
      "538/538 - 207s - loss: 0.3695 - auc: 0.9142 - val_loss: 0.3659 - val_auc: 0.9162 - lr: 0.0010 - 207s/epoch - 384ms/step\n",
      "Epoch 30/50\n",
      "538/538 - 184s - loss: 0.3646 - auc: 0.9163 - val_loss: 0.3722 - val_auc: 0.9138 - lr: 0.0010 - 184s/epoch - 342ms/step\n",
      "Epoch 31/50\n",
      "538/538 - 183s - loss: 0.3616 - auc: 0.9179 - val_loss: 0.3652 - val_auc: 0.9169 - lr: 0.0010 - 183s/epoch - 341ms/step\n",
      "Epoch 32/50\n",
      "538/538 - 180s - loss: 0.3596 - auc: 0.9187 - val_loss: 0.3641 - val_auc: 0.9181 - lr: 0.0010 - 180s/epoch - 335ms/step\n",
      "Epoch 33/50\n",
      "538/538 - 199s - loss: 0.3550 - auc: 0.9209 - val_loss: 0.3590 - val_auc: 0.9199 - lr: 0.0010 - 199s/epoch - 369ms/step\n",
      "Epoch 34/50\n",
      "538/538 - 188s - loss: 0.3553 - auc: 0.9209 - val_loss: 0.3612 - val_auc: 0.9185 - lr: 0.0010 - 188s/epoch - 350ms/step\n",
      "Epoch 35/50\n",
      "538/538 - 189s - loss: 0.3484 - auc: 0.9241 - val_loss: 0.3564 - val_auc: 0.9207 - lr: 0.0010 - 189s/epoch - 351ms/step\n",
      "Epoch 36/50\n",
      "538/538 - 195s - loss: 0.3495 - auc: 0.9233 - val_loss: 0.3569 - val_auc: 0.9222 - lr: 0.0010 - 195s/epoch - 362ms/step\n",
      "Epoch 37/50\n",
      "538/538 - 206s - loss: 0.3449 - auc: 0.9255 - val_loss: 0.3562 - val_auc: 0.9223 - lr: 0.0010 - 206s/epoch - 383ms/step\n",
      "Epoch 38/50\n",
      "538/538 - 173s - loss: 0.3431 - auc: 0.9264 - val_loss: 0.3535 - val_auc: 0.9223 - lr: 0.0010 - 173s/epoch - 321ms/step\n",
      "Epoch 39/50\n",
      "538/538 - 171s - loss: 0.3413 - auc: 0.9269 - val_loss: 0.3494 - val_auc: 0.9248 - lr: 0.0010 - 171s/epoch - 317ms/step\n",
      "Epoch 40/50\n",
      "538/538 - 171s - loss: 0.3410 - auc: 0.9274 - val_loss: 0.3473 - val_auc: 0.9252 - lr: 0.0010 - 171s/epoch - 318ms/step\n",
      "Epoch 41/50\n",
      "538/538 - 174s - loss: 0.3329 - auc: 0.9308 - val_loss: 0.3514 - val_auc: 0.9239 - lr: 0.0010 - 174s/epoch - 323ms/step\n",
      "Epoch 42/50\n",
      "538/538 - 172s - loss: 0.3380 - auc: 0.9288 - val_loss: 0.3496 - val_auc: 0.9256 - lr: 0.0010 - 172s/epoch - 320ms/step\n",
      "Epoch 43/50\n",
      "538/538 - 174s - loss: 0.3306 - auc: 0.9318 - val_loss: 0.3474 - val_auc: 0.9254 - lr: 0.0010 - 174s/epoch - 324ms/step\n",
      "Epoch 44/50\n",
      "538/538 - 269s - loss: 0.3293 - auc: 0.9324 - val_loss: 0.3380 - val_auc: 0.9299 - lr: 0.0010 - 269s/epoch - 501ms/step\n",
      "Epoch 45/50\n",
      "538/538 - 187s - loss: 0.3279 - auc: 0.9329 - val_loss: 0.3439 - val_auc: 0.9277 - lr: 0.0010 - 187s/epoch - 348ms/step\n",
      "Epoch 46/50\n",
      "538/538 - 189s - loss: 0.3280 - auc: 0.9328 - val_loss: 0.3407 - val_auc: 0.9294 - lr: 0.0010 - 189s/epoch - 350ms/step\n",
      "Epoch 47/50\n",
      "538/538 - 177s - loss: 0.3233 - auc: 0.9352 - val_loss: 0.3408 - val_auc: 0.9288 - lr: 0.0010 - 177s/epoch - 329ms/step\n",
      "Epoch 48/50\n",
      "538/538 - 170s - loss: 0.3200 - auc: 0.9364 - val_loss: 0.3386 - val_auc: 0.9300 - lr: 0.0010 - 170s/epoch - 316ms/step\n",
      "Epoch 49/50\n",
      "538/538 - 169s - loss: 0.3207 - auc: 0.9361 - val_loss: 0.3368 - val_auc: 0.9308 - lr: 0.0010 - 169s/epoch - 313ms/step\n",
      "Epoch 50/50\n",
      "538/538 - 168s - loss: 0.3188 - auc: 0.9369 - val_loss: 0.3338 - val_auc: 0.9324 - lr: 0.0010 - 168s/epoch - 312ms/step\n",
      "\n",
      " training process done!!\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "print('begin training process')\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=10, verbose=1, min_lr=1e-6)\n",
    "#callbacks = [lr_scheduler]\n",
    "model.fit(X_train, y_train, batch_size = 48, epochs = 50, validation_data=(X_val, y_val), \n",
    "         verbose = 2)\n",
    "print('\\n training process done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "538/538 - 199s - loss: 0.4246 - auc: 0.8850 - val_loss: 0.4223 - val_auc: 0.8878 - 199s/epoch - 369ms/step\n",
      "Epoch 2/50\n",
      "538/538 - 199s - loss: 0.4241 - auc: 0.8856 - val_loss: 0.4261 - val_auc: 0.8868 - 199s/epoch - 370ms/step\n",
      "Epoch 3/50\n",
      "538/538 - 201s - loss: 0.4164 - auc: 0.8898 - val_loss: 0.4219 - val_auc: 0.8897 - 201s/epoch - 374ms/step\n",
      "Epoch 4/50\n",
      "538/538 - 199s - loss: 0.4157 - auc: 0.8902 - val_loss: 0.4134 - val_auc: 0.8924 - 199s/epoch - 370ms/step\n",
      "Epoch 5/50\n",
      "538/538 - 184s - loss: 0.4104 - auc: 0.8930 - val_loss: 0.4123 - val_auc: 0.8936 - 184s/epoch - 342ms/step\n",
      "Epoch 6/50\n",
      "538/538 - 174s - loss: 0.4086 - auc: 0.8940 - val_loss: 0.4065 - val_auc: 0.8953 - 174s/epoch - 324ms/step\n",
      "Epoch 7/50\n",
      "538/538 - 172s - loss: 0.4042 - auc: 0.8965 - val_loss: 0.4099 - val_auc: 0.8956 - 172s/epoch - 320ms/step\n",
      "Epoch 8/50\n",
      "538/538 - 178s - loss: 0.4018 - auc: 0.8979 - val_loss: 0.4018 - val_auc: 0.8983 - 178s/epoch - 330ms/step\n",
      "Epoch 9/50\n",
      "538/538 - 172s - loss: 0.3982 - auc: 0.8997 - val_loss: 0.3977 - val_auc: 0.9005 - 172s/epoch - 319ms/step\n",
      "Epoch 10/50\n",
      "538/538 - 171s - loss: 0.3957 - auc: 0.9010 - val_loss: 0.3963 - val_auc: 0.9014 - 171s/epoch - 317ms/step\n",
      "Epoch 11/50\n",
      "538/538 - 172s - loss: 0.3907 - auc: 0.9038 - val_loss: 0.3919 - val_auc: 0.9036 - 172s/epoch - 319ms/step\n",
      "Epoch 12/50\n",
      "538/538 - 172s - loss: 0.3912 - auc: 0.9035 - val_loss: 0.3905 - val_auc: 0.9042 - 172s/epoch - 320ms/step\n",
      "Epoch 13/50\n",
      "538/538 - 171s - loss: 0.3868 - auc: 0.9059 - val_loss: 0.3884 - val_auc: 0.9063 - 171s/epoch - 318ms/step\n",
      "Epoch 14/50\n",
      "538/538 - 172s - loss: 0.3846 - auc: 0.9068 - val_loss: 0.3881 - val_auc: 0.9061 - 172s/epoch - 319ms/step\n",
      "Epoch 15/50\n",
      "538/538 - 170s - loss: 0.3820 - auc: 0.9082 - val_loss: 0.3795 - val_auc: 0.9095 - 170s/epoch - 317ms/step\n",
      "Epoch 16/50\n",
      "538/538 - 168s - loss: 0.3772 - auc: 0.9107 - val_loss: 0.3823 - val_auc: 0.9090 - 168s/epoch - 313ms/step\n",
      "Epoch 17/50\n",
      "538/538 - 168s - loss: 0.3735 - auc: 0.9125 - val_loss: 0.3870 - val_auc: 0.9098 - 168s/epoch - 312ms/step\n",
      "Epoch 18/50\n",
      "538/538 - 169s - loss: 0.4114 - auc: 0.8925 - val_loss: 0.3988 - val_auc: 0.9001 - 169s/epoch - 314ms/step\n",
      "Epoch 19/50\n",
      "538/538 - 169s - loss: 0.3922 - auc: 0.9030 - val_loss: 0.3881 - val_auc: 0.9067 - 169s/epoch - 313ms/step\n",
      "Epoch 20/50\n",
      "538/538 - 173s - loss: 0.3794 - auc: 0.9092 - val_loss: 0.3743 - val_auc: 0.9120 - 173s/epoch - 322ms/step\n",
      "Epoch 21/50\n",
      "538/538 - 168s - loss: 0.3725 - auc: 0.9130 - val_loss: 0.3763 - val_auc: 0.9124 - 168s/epoch - 313ms/step\n",
      "Epoch 22/50\n",
      "538/538 - 168s - loss: 0.3693 - auc: 0.9143 - val_loss: 0.3698 - val_auc: 0.9147 - 168s/epoch - 313ms/step\n",
      "Epoch 23/50\n",
      "538/538 - 168s - loss: 0.3701 - auc: 0.9140 - val_loss: 0.3723 - val_auc: 0.9154 - 168s/epoch - 313ms/step\n",
      "Epoch 24/50\n",
      "538/538 - 177s - loss: 0.3667 - auc: 0.9154 - val_loss: 0.3646 - val_auc: 0.9173 - 177s/epoch - 329ms/step\n",
      "Epoch 25/50\n",
      "538/538 - 175s - loss: 0.3652 - auc: 0.9163 - val_loss: 0.3689 - val_auc: 0.9171 - 175s/epoch - 326ms/step\n",
      "Epoch 26/50\n",
      "538/538 - 187s - loss: 0.3627 - auc: 0.9175 - val_loss: 0.3722 - val_auc: 0.9174 - 187s/epoch - 348ms/step\n",
      "Epoch 27/50\n",
      "538/538 - 185s - loss: 0.3594 - auc: 0.9191 - val_loss: 0.3578 - val_auc: 0.9209 - 185s/epoch - 343ms/step\n",
      "Epoch 28/50\n",
      "538/538 - 188s - loss: 0.3538 - auc: 0.9216 - val_loss: 0.3560 - val_auc: 0.9212 - 188s/epoch - 349ms/step\n",
      "Epoch 29/50\n",
      "538/538 - 171s - loss: 0.3546 - auc: 0.9214 - val_loss: 0.3541 - val_auc: 0.9232 - 171s/epoch - 319ms/step\n",
      "Epoch 30/50\n",
      "538/538 - 177s - loss: 0.3488 - auc: 0.9240 - val_loss: 0.3494 - val_auc: 0.9242 - 177s/epoch - 329ms/step\n",
      "Epoch 31/50\n",
      "538/538 - 185s - loss: 0.3457 - auc: 0.9252 - val_loss: 0.3461 - val_auc: 0.9255 - 185s/epoch - 343ms/step\n",
      "Epoch 32/50\n",
      "538/538 - 186s - loss: 0.3472 - auc: 0.9246 - val_loss: 0.3495 - val_auc: 0.9240 - 186s/epoch - 346ms/step\n",
      "Epoch 33/50\n",
      "538/538 - 189s - loss: 0.3447 - auc: 0.9256 - val_loss: 0.3446 - val_auc: 0.9263 - 189s/epoch - 352ms/step\n",
      "Epoch 34/50\n",
      "538/538 - 191s - loss: 0.3421 - auc: 0.9271 - val_loss: 0.3486 - val_auc: 0.9259 - 191s/epoch - 356ms/step\n",
      "Epoch 35/50\n",
      "538/538 - 198s - loss: 0.3436 - auc: 0.9261 - val_loss: 0.3538 - val_auc: 0.9259 - 198s/epoch - 368ms/step\n",
      "Epoch 36/50\n",
      "538/538 - 194s - loss: 0.3379 - auc: 0.9287 - val_loss: 0.3419 - val_auc: 0.9281 - 194s/epoch - 360ms/step\n",
      "Epoch 37/50\n",
      "538/538 - 176s - loss: 0.3383 - auc: 0.9286 - val_loss: 0.3395 - val_auc: 0.9290 - 176s/epoch - 327ms/step\n",
      "Epoch 38/50\n",
      "538/538 - 175s - loss: 0.3318 - auc: 0.9311 - val_loss: 0.3411 - val_auc: 0.9292 - 175s/epoch - 326ms/step\n",
      "Epoch 39/50\n",
      "538/538 - 178s - loss: 0.3281 - auc: 0.9331 - val_loss: 0.3349 - val_auc: 0.9316 - 178s/epoch - 331ms/step\n",
      "Epoch 40/50\n",
      "538/538 - 172s - loss: 0.3302 - auc: 0.9319 - val_loss: 0.3370 - val_auc: 0.9308 - 172s/epoch - 320ms/step\n",
      "Epoch 41/50\n",
      "538/538 - 171s - loss: 0.3244 - auc: 0.9346 - val_loss: 0.3388 - val_auc: 0.9317 - 171s/epoch - 318ms/step\n",
      "Epoch 42/50\n",
      "538/538 - 172s - loss: 0.3261 - auc: 0.9336 - val_loss: 0.3268 - val_auc: 0.9343 - 172s/epoch - 320ms/step\n",
      "Epoch 43/50\n",
      "538/538 - 175s - loss: 0.3230 - auc: 0.9350 - val_loss: 0.3327 - val_auc: 0.9328 - 175s/epoch - 326ms/step\n",
      "Epoch 44/50\n",
      "538/538 - 179s - loss: 0.3214 - auc: 0.9353 - val_loss: 0.3333 - val_auc: 0.9328 - 179s/epoch - 332ms/step\n",
      "Epoch 45/50\n",
      "538/538 - 178s - loss: 0.3229 - auc: 0.9351 - val_loss: 0.3213 - val_auc: 0.9367 - 178s/epoch - 331ms/step\n",
      "Epoch 46/50\n",
      "538/538 - 175s - loss: 0.3173 - auc: 0.9373 - val_loss: 0.3208 - val_auc: 0.9369 - 175s/epoch - 326ms/step\n",
      "Epoch 47/50\n",
      "538/538 - 179s - loss: 0.3153 - auc: 0.9383 - val_loss: 0.3219 - val_auc: 0.9366 - 179s/epoch - 332ms/step\n",
      "Epoch 48/50\n",
      "538/538 - 177s - loss: 0.3171 - auc: 0.9375 - val_loss: 0.3204 - val_auc: 0.9375 - 177s/epoch - 330ms/step\n",
      "Epoch 49/50\n",
      "538/538 - 180s - loss: 0.3133 - auc: 0.9390 - val_loss: 0.3139 - val_auc: 0.9398 - 180s/epoch - 335ms/step\n",
      "Epoch 50/50\n",
      "538/538 - 179s - loss: 0.3120 - auc: 0.9396 - val_loss: 0.3184 - val_auc: 0.9391 - 179s/epoch - 333ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=48, verbose = 2)\n",
    "\n",
    "plt.plot(range(1, 50 + 1), history.history['loss'], label='Training Loss')\n",
    "plt.plot(range(1, 50 + 1), history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 6s 23ms/step - loss: 0.3098 - auc: 0.9413\n",
      "Loss:  0.3097611665725708 Auc:  0.9412671327590942\n"
     ]
    }
   ],
   "source": [
    "loss, auc = model.evaluate(X_test, y_test)\n",
    "\n",
    "\n",
    "print('Loss: ', str(loss) , 'Auc: ', str(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Conclusion, Challenges, And What I Would Improve</h1>\n",
    "\n",
    "Overall I'm really happy with how this model turned out, orginailly this was supposed to be with book data reviews but that had much less data and I ended up with only a few thousand trainable params by the end of it, because I didn't have much data my model had a lot of bias and wasn't performing well.\n",
    "\n",
    "I wanted to prove the concept of using word embeddings in a recurrent neural network so I'm glad that I changed the dataset.\n",
    "\n",
    "<h3>Biggest Challenge</h3>\n",
    "My biggest challenge with this problem was for the gridsearch function when I was trying to build the shell of the model that I would use in the gridsearch, I couldn't get the kerasClassifer to import to create a the estimator model so I had to create a function myself that during the training process would assign a blank model different hyperparameters to try out and see which combination is best. \n",
    "\n",
    "<h2>Things to improve.......</h2>\n",
    "\n",
    "\n",
    "I originally used lr_scheduling which decreases the learning rate by 5% if the validation loss doesn't improve over 10 epochs, howeveer the val_loss was improving anyways over 10 epochs so there wasn't really a need to add it and it made training time exponentially longer. \n",
    "\n",
    "In general I think this model took far too long to train (several hours) so I would probably look into how much I can downsample the data without sacrificing performance (paralell processing isn't available for me because im on a laptop thats not very powerful)\n",
    "\n",
    "I would like to add batch normalization (whcihc rescales the input data to have a mean of 0 and sd of 1) this is supposed to make training much faster because now it takes around 10 hours to train this model. Batch normalization mititgates internal covariate shift (all input has different distrivutions and it takes time to account for that in the model)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
